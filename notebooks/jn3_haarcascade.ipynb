{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6527421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2 # for OpenCV bindings.\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import imutils # for OpenCV convenience functions.\n",
    "import code3_data as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bca50ed",
   "metadata": {},
   "source": [
    "## HAAR CASCADE CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a0a951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../src/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('../src/haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('../src/haarcascade_smile.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55af833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_demo = Path.cwd().parent/'demo'\n",
    "dir_demo_faces = Path.cwd().parent/'demo_faces'\n",
    "dir_imgs= Path.cwd().parent/'imgs'\n",
    "dir_imgs_faces = Path.cwd().parent/'imgs_faces'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d7bd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HAAR CASCADE CLASSIFIER from directory with .jpg images\n",
    "go.detect_face_eyes_smile(dir_demo)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "823be13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRIS: try out cnn from opencv! check: first one is normal haar, second is deeplearninh improved\n",
    "    # https://www.pyimagesearch.com/2021/04/05/opencv-face-detection-with-haar-cascades/\n",
    "    # https://www.pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/"
   ]
  },
  {
   "source": [
    "            "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "341e03d5",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a37235c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c01f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e7bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c38fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67423fc8",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee603cf9",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa58343",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b79c66d",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebbf94b",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db786694",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce07c9",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e558b68",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d88b470",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39489ec7",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7e0525",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1100ec8d",
   "metadata": {},
   "source": [
    "# FUNCTION ONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ad0ed9",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289499a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openImageAndDetectFaces3(paaath):\n",
    "    \n",
    "    for file in sorted(paaath.iterdir()):\n",
    "        \n",
    "        if file.suffix == '.jpg':\n",
    "            \n",
    "            image = face_recognition.load_image_file(file)\n",
    "            face_locations = face_recognition.face_locations(image)\n",
    "            count = 0\n",
    "            \n",
    "            try:\n",
    "                #print(f\"I found {len(face_locations)} face(s) in photograph {file.name}.\")\n",
    "                #plt.subplot(121)\n",
    "                #plt.imshow(image)\n",
    "                \n",
    "                for feis in face_locations:\n",
    "                    count+=1\n",
    "                    top, right, bottom, left = feis\n",
    "                    face_image = image[top:bottom, left:right]\n",
    "                    face_image = cv2.cvtColor(face_image, cv2.COLOR_RGB2GRAY)\n",
    "                    pil_image = Image.fromarray(face_image)\n",
    "                    reshaped_image = modify_size(pil_image)\n",
    "\n",
    "                    file_face = file.name.replace(\".\",f\"_face{count}.\")\n",
    "                    file_pil = file.name.replace(\".\",f\"_pil{count}.\")\n",
    "                    file_reshaped = file.name.replace(\".\",f\"_reshaped{count}.\")\n",
    "                    cv2.imwrite(str(folder_faces/file_face), face_image)\n",
    "                    \n",
    "                    #fig, axarr = plt.subplots(len(face_locations),1)\n",
    "                    #plt.subplot(121)\n",
    "                    #plt.imshow(new_size(pil_image))\n",
    "                    #f.name.replace(\".\",f\"_face{count}.\")\n",
    "                    #cv2.imwrite(str(folder_faces/file_pil), pil_image)\n",
    "                    #cv2.imwrite(str(folder_faces/file_reshaped), reshaped_image)\n",
    "                    #cv2.imwrite(str(folder_faces/file.name)+f\"_face{count}\", face_image)\n",
    "                    #return new_size(pil_image)\n",
    "            \n",
    "            except ValueError as e:\n",
    "                print(f\"No face found\")\n",
    "                \n",
    "    return reshaped_image\n",
    "\n",
    "        \n",
    "def modify_size(img):\n",
    "    size=(48,48)\n",
    "    convert_from = img.resize(size)\n",
    "    face=np.asarray(convert_from)/255\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4dae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "face = openImageAndDetectFaces3(folder_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0206accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('say -v Jorge Ya he terminado');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5eab0f",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e63621",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093060a4",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbaf5b7",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab668d",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eacde9",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc7955",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f026643",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be3b38f",
   "metadata": {},
   "source": [
    "# FUNCTION TWO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625fb5c6",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a63d900",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_col = Image.open(pth)\n",
    "image_blues = cv2.imread(pth)\n",
    "image_greens = cv2.cvtColor(image_blues, cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f720c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(image_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fd9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(pth)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# now we can try to detect faces\n",
    "faces = face_cascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=5,\n",
    "    minSize=(30, 30),\n",
    "    #flags = cv2.CASCADE_SCALE_IMAGE\n",
    ")\n",
    "\n",
    "for feis in faces:\n",
    "    print(feis)\n",
    "# Draw a rectangle around the faces and display on screen\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        #cv2.imshow(\"Faces found\", image)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "    #print(flags)\n",
    "        #cv2.resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e5e353",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc4af68",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedda70e",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb9db86",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc190ad",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ceab81",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310b8a7b",
   "metadata": {},
   "source": [
    "### FUNCTION TWO-A ¿?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280fcc54",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca87a80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(image_blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b05b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(image_blues))\n",
    "print('len(image_blues): ',len(image_blues))\n",
    "print('image_blues.shape: ',image_blues.shape)\n",
    "print('len(image_blues)[0]: ',len(image_blues[0]))\n",
    "print('image_blues[0]: ',image_blues[0])\n",
    "print('image_blues[0][0]: ',image_blues[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e07c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_blue = face_cascade.detectMultiScale(\n",
    "    image_blues,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=5,\n",
    "    minSize=(30, 30),\n",
    "    #flags = cv2.CASCADE_SCALE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6d56aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(type(faces_blue))\n",
    "print('len(faces_blue): ',len(faces_blue))\n",
    "print('faces_blue.shape: ',faces_blue.shape)\n",
    "print('len(faces_blue)[0]: ',len(faces_blue[0]))\n",
    "print('faces_blue[0]: ',faces_blue[0])\n",
    "print('faces_blue: ',faces_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y, w, h) in faces_blue:\n",
    "    rec_blue = cv2.rectangle(image_blues, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    print(rec_blue[0])\n",
    "    print(rec_blue.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_blue = image_blues\n",
    "rostro_blue = aux_blue[y:y+h,x:x+w]\n",
    "rostro_blue = cv2.resize(rostro_blue,(150,150),interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b55482",
   "metadata": {},
   "outputs": [],
   "source": [
    "rostro_blue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd7a38b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(rostro_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bfddf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(image_blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0155a4a5",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a77d53",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8315eda5",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2802b89",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030a9365",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737f402e",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa68e81",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dc34d3",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441be51e",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918a16c",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3959efe6",
   "metadata": {},
   "source": [
    "### FUNCTION TWO-B ¿?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cd997b",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424cb530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(image_greens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e441e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAY = IMAGE_GREENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6987a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(image_greens))\n",
    "print('len(image_greens): ',len(image_greens))\n",
    "print('image_greens.shape: ',image_greens.shape)\n",
    "print('len(image_greens)[0]: ',len(image_greens[0]))\n",
    "print('image_greens[0]: ',image_greens[0])\n",
    "print('image_greens[0][0]: ',image_greens[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99063ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_green = face_cascade.detectMultiScale(\n",
    "    image_greens,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=5,\n",
    "    minSize=(30, 30),\n",
    "    #flags = cv2.CASCADE_SCALE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(faces_green))\n",
    "print('len(faces_green): ',len(faces_green))\n",
    "print('faces_green.shape: ',faces_green.shape)\n",
    "print('len(faces_green)[0]: ',len(faces_green[0]))\n",
    "print('faces_green[0]: ',faces_green[0])\n",
    "print('faces_green: ',faces_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5213a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x, y, w, h) in faces_green:\n",
    "    rec_green = cv2.rectangle(image_greens, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    print(rec_green)\n",
    "    print(rec_green.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfa1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_green = image_greens\n",
    "rostro_green = aux_green[y:y+h,x:x+w]\n",
    "rostro_green = cv2.resize(rostro_green,(150,150),interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c9b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rostro_green.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb6508",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rostro_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be4f02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(image_greens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63304a4c",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cd3d66",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554f9f40",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fabd508",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f93ef1",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec05f22",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeb67cf",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f47f2d",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ba1dd",
   "metadata": {},
   "source": [
    "### EXTRA STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a623afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pth = \"../imgs/\"\n",
    "file = \"im14\"\n",
    "ext = \".jpg\"\n",
    "ab_pth = pth+file+ext\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a363c7",
   "metadata": {},
   "source": [
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a8dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openImageAndDetectFaces1(path):\n",
    "    image = face_recognition.load_image_file(path)\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "    try:\n",
    "        print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "        plt.imshow(image)\n",
    "        for face_location in face_locations:\n",
    "            top, right, bottom, left = face_location\n",
    "            face_image = image[top:bottom, left:right]\n",
    "            face_image = cv2.cvtColor(face_image, cv2.COLOR_RGB2GRAY)\n",
    "            pil_image = Image.fromarray(face_image)\n",
    "            #plt.imshow(pil_image)\n",
    "            fig, axarr = plt.subplots(len(face_locations),1)\n",
    "            plt.subplot(121)\n",
    "            plt.imshow(modify_size(pil_image))\n",
    "        #return modify_size(pil_image)\n",
    "    except ValueError as e:\n",
    "        print(f\"No face found\")\n",
    "        \n",
    "        \n",
    "def modify_size(img):\n",
    "    size=(48,48)\n",
    "    convert_from = img.resize(size)\n",
    "    face=np.asarray(convert_from)/255\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad234fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "face = openImageAndDetectFaces1(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea2c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = \"../imgs/\"\n",
    "file = \"im_10\"\n",
    "ext = \".jpg\"\n",
    "ab_pth = pth+file+ext\n",
    "\n",
    "def openImageAndDetectFaces2(ab_pth):\n",
    "    \n",
    "    image = face_recognition.load_image_file(ab_pth)\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "    count = 0\n",
    "    try:\n",
    "        print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "        #plt.subplot(121)\n",
    "        plt.imshow(image)\n",
    "        for feis in face_locations:\n",
    "            count+=1\n",
    "            top, right, bottom, left = feis\n",
    "            face_image = image[top:bottom, left:right]\n",
    "            face_image = cv2.cvtColor(face_image, cv2.COLOR_RGB2GRAY)\n",
    "            pil_image = Image.fromarray(face_image)\n",
    "            fig, axarr = plt.subplots(len(face_locations),1)\n",
    "            #plt.subplot(121)\n",
    "            #plt.imshow(image)\n",
    "            plt.subplot(121)\n",
    "            plt.imshow(new_size(pil_image))\n",
    "            #image_name = os.path.join(subfolder, '{:05d}.jpg'.format(i))\n",
    "            #im.save(image_name)\n",
    "            #print(pil_image)\n",
    "            face_in_pic_pth = pth+file+f\"_face{count}\"+ext\n",
    "            cv2.imwrite(face_in_pic_pth, face_image)\n",
    "            print(face_in_pic_pth)\n",
    "            #return new_size(pil_image)\n",
    "    except ValueError as e:\n",
    "        print(f\"No face found\")\n",
    "        return pil_image\n",
    "     \n",
    "        \n",
    "def new_size(img):\n",
    "    size=(48,48)\n",
    "    convert_from = img.resize(size)\n",
    "    face=np.asarray(convert_from)/255\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2869c80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "face = openImageAndDetectFaces2(\"../imgs/im_10.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d5e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT DONE\n",
    "def openImageAndDetectFaces_HAAS(paaath):\n",
    "    for file in sorted(paaath.iterdir()):\n",
    "        if file.suffix == '.jpg':\n",
    "            count = 0\n",
    "            \n",
    "            image = face_recognition.load_image_file(file)\n",
    "            face_locations = face_recognition.face_locations(image)\n",
    "            \n",
    "            \n",
    "            img = cv2.imread(file)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            auxFrame = img.copy()\n",
    "            \n",
    "            try:\n",
    "                #print(f\"I found {len(face_locations)} face(s) in photograph {file.name}.\")\n",
    "                #plt.subplot(121)\n",
    "                #plt.imshow(image)\n",
    "                \n",
    "                # PRIMER APPROACH\n",
    "                \n",
    "                for feis in face_locations:\n",
    "                    count+=1\n",
    "                    top, right, bottom, left = feis\n",
    "                    face_image = image[top:bottom, left:right]\n",
    "                    face_image = cv2.cvtColor(face_image, cv2.COLOR_RGB2GRAY)\n",
    "                     \n",
    "                    jeanchas_gray = face_image.copy()\n",
    "                    jeanchas_faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "                    \n",
    "                    for (x,y,w,h) in jeanchas_faces:\n",
    "                        cv2.rectangle(file, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                        rostro = auxFrame[y:y+h,x:x+w]\n",
    "                        rostro = cv2.resize(rostro,(150,150),interpolation=cv2.INTER_CUBIC)\n",
    "                        file_rostro = file.name.replace(\".\",f\"_rostro{count}.\")\n",
    "                        cv2.imwrite(str(folder_faces/file_rostro), rostro)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    pil_image = Image.fromarray(face_image)\n",
    "                    reshaped_image = modify_size(pil_image)\n",
    "                    #fig, axarr = plt.subplots(len(face_locations),1)\n",
    "                    #plt.subplot(121)\n",
    "                    #plt.imshow(new_size(pil_image))\n",
    "                    f.name.replace(\".\",f\"_face{count}.\")\n",
    "                    file_face = file.name.replace(\".\",f\"_face{count}.\")\n",
    "                    cv2.imwrite(str(folder_faces/file_face), face_image)\n",
    "                    \n",
    "                    file_pil = file.name.replace(\".\",f\"_pil{count}.\")\n",
    "                    file_reshaped = file.name.replace(\".\",f\"_reshaped{count}.\")\n",
    "                    \n",
    "                    \n",
    "                    file_rostro = file.name.replace(\".\",f\"_rostro{count}.\")\n",
    "                    cv2.imwrite(str(folder_faces/file_rostro), rostro)\n",
    "                    #cv2.imwrite(str(folder_faces/file_pil), pil_image)\n",
    "                    #cv2.imwrite(str(folder_faces/file_reshaped), reshaped_image)\n",
    "                    #cv2.imwrite(str(folder_faces/file.name)+f\"_face{count}\", face_image)\n",
    "                \n",
    "                # SEGUNDO APPROACH\n",
    "                \n",
    "                for (x,y,w,h) in file:\n",
    "                    x,y,w,h = rostro2\n",
    "                    cv2.rectangle(file, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                    \n",
    "                    rostro = auxFrame[y:y+h,x:x+w]\n",
    "                    rostro = cv2.resize(rostro,(150,150),interpolation=cv2.INTER_CUBIC)\n",
    "                    file_rostro = file.name.replace(\".\",f\"_rostro{count}.\")\n",
    "                    cv2.imwrite(str(folder_faces/file_rostro), rostro)\n",
    "                    \n",
    "                    #return new_size(pil_image)\n",
    "            except ValueError as e:\n",
    "                print(f\"No face found\")\n",
    "                \n",
    "    return reshaped_image\n",
    "\n",
    "        \n",
    "def modify_size(img):\n",
    "    size=(48,48)\n",
    "    convert_from = img.resize(size)\n",
    "    face=np.asarray(convert_from)/255\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba1d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "openImageAndDetectFaces_HAAS(folder_imgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iron",
   "language": "python",
   "name": "iron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}