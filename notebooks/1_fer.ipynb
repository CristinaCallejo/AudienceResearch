{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4552b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "#os.sys.path\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplt\n",
    "import code1_data as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a1f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1_path = Path.home()/'Iron'/'inp1'\n",
    "\n",
    "train_path = inp1_path/'train'\n",
    "\n",
    "testvalidation_path = inp1_path/'test_validation'\n",
    "\n",
    "fer_csv = inp1_path/'Fer.csv'\n",
    "\n",
    "train_csv = train_path/'Training_Data.csv'\n",
    "\n",
    "test_csv = testvalidation_path/'Testing_Data.csv'\n",
    "\n",
    "validation_csv = testvalidation_path/'Validation_Data.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853520e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fer = pd.read_csv(fer_csv,encoding = \"ISO-8859-1\")\n",
    "df_train = pd.read_csv(train_csv,encoding = \"ISO-8859-1\")\n",
    "df_test = pd.read_csv(test_csv,encoding = \"ISO-8859-1\")\n",
    "df_val = pd.read_csv(validation_csv,encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff49202",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ('angry','disgust','fear','happy','sad','surprise','neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc846bc",
   "metadata": {},
   "source": [
    "## fer2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2acdc633",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_fer.copy( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0530a089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35887, 3) 107661 Index(['emotion', 'pixels', 'Usage'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.shape, df.size, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91efc9e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_size=(48,48)\n",
    "pixels = df['pixels'].tolist() # Converting the relevant column element into a list for each row\n",
    "width, height = 48, 48\n",
    "faces = []\n",
    "\n",
    "for pixel_sequence in pixels:\n",
    "    face = [int(pixel) for pixel in pixel_sequence.split(' ')] # Splitting the string by space character as a list\n",
    "    face = np.asarray(face).reshape(width, height) #converting the list to numpy array in size of 48*48\n",
    "    face = cv2.resize(face.astype('uint8'),image_size) #resize the image to have 48 cols (width) and 48 rows (height)\n",
    "    faces.append(face.astype('float32')) #makes the list of each images of 48*48 and their pixels in numpyarray form\n",
    "\n",
    "faces = np.asarray(faces) #converting the list into numpy array\n",
    "faces = np.expand_dims(faces, -1) #Expand the shape of an array -1=last dimension => means color space\n",
    "emotions = pd.get_dummies(df['emotion']).to_numpy() #doing the one hot encoding type on emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe39dfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48, 1)\n",
      "(35887, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "print(faces[0].shape)\n",
    "print(faces.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cdad64",
   "metadata": {},
   "source": [
    "### Standardize or Normalize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e17e1a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize (from 0 to 1)\n",
    "x = faces.astype('float32')\n",
    "x = x / 255.0\n",
    "\n",
    "# scale pixel value (from -1 to 1)\n",
    "x = x - 0.5\n",
    "x = x * 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "467687f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a11bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "q,t = emotions.shape\n",
    "q = len(x)\n",
    "q_train = int((0.8) * q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406cf602",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d94fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "train_x = x[:q_train]\n",
    "train_y = emotions[:q_train]\n",
    "\n",
    "# Validation data\n",
    "val_x = x[q_train:]\n",
    "val_y = emotions[q_train:]\n",
    "\n",
    "train_data = (train_x, train_y)\n",
    "val_data = (val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdc82ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "train_x.shape (pixels):  (28709, 48, 48, 1)\n",
      "\n",
      "\n",
      "train_y.shape: (labels):  (28709, 7)\n",
      "\n",
      "\n",
      "val_x.shape (pixels):  (7178, 48, 48, 1)\n",
      "\n",
      "\n",
      "val_y.shape: (labels):  (7178, 7)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "print('train_x.shape (pixels): ',train_x.shape)  # ==> 4 dims -  no of images , width , height , color\n",
    "print(\"\\n\")\n",
    "print('train_y.shape: (labels): ',train_y.shape)\n",
    "print(\"\\n\")\n",
    "print('val_x.shape (pixels): ',val_x.shape)\n",
    "print(\"\\n\")\n",
    "print('val_y.shape: (labels): ',val_y.shape)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a9af996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.45098037],\n",
       "        [-0.372549  ],\n",
       "        [-0.35686272],\n",
       "        ...,\n",
       "        [-0.5921569 ],\n",
       "        [-0.6627451 ],\n",
       "        [-0.6784314 ]],\n",
       "\n",
       "       [[-0.49019605],\n",
       "        [-0.52156866],\n",
       "        [-0.54509807],\n",
       "        ...,\n",
       "        [-0.56078434],\n",
       "        [-0.5921569 ],\n",
       "        [-0.654902  ]],\n",
       "\n",
       "       [[-0.60784316],\n",
       "        [-0.6627451 ],\n",
       "        [-0.5764706 ],\n",
       "        ...,\n",
       "        [-0.6156863 ],\n",
       "        [-0.56078434],\n",
       "        [-0.6313726 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.2862745 ],\n",
       "        [-0.49019605],\n",
       "        [-0.67058825],\n",
       "        ...,\n",
       "        [-0.4352941 ],\n",
       "        [-0.56078434],\n",
       "        [-0.6627451 ]],\n",
       "\n",
       "       [[-0.3960784 ],\n",
       "        [-0.35686272],\n",
       "        [-0.38039213],\n",
       "        ...,\n",
       "        [-0.17647058],\n",
       "        [-0.45098037],\n",
       "        [-0.6392157 ]],\n",
       "\n",
       "       [[-0.3960784 ],\n",
       "        [-0.4352941 ],\n",
       "        [-0.34117645],\n",
       "        ...,\n",
       "        [-0.16862744],\n",
       "        [-0.14509803],\n",
       "        [-0.35686272]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf88bd8",
   "metadata": {},
   "source": [
    "## predict(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd67d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67ec77f5",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0d9e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iron",
   "language": "python",
   "name": "iron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
