{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bee3ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "#os.sys.path\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplt\n",
    "import code1_data as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6660cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1_path = Path.home()/'Iron'/'inp1'\n",
    "\n",
    "train_path = inp1_path/'train'\n",
    "\n",
    "testvalidation_path = inp1_path/'test_validation'\n",
    "\n",
    "fer_csv = inp1_path/'Fer.csv'\n",
    "\n",
    "train_csv = train_path/'Training_Data.csv'\n",
    "\n",
    "test_csv = testvalidation_path/'Testing_Data.csv'\n",
    "\n",
    "validation_csv = testvalidation_path/'Validation_Data.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "359e3b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fer = pd.read_csv(fer_csv,encoding = \"ISO-8859-1\")\n",
    "df_train = pd.read_csv(train_csv,encoding = \"ISO-8859-1\")\n",
    "df_test = pd.read_csv(test_csv,encoding = \"ISO-8859-1\")\n",
    "df_val = pd.read_csv(validation_csv,encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ac0ed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ('angry','disgust','fear','happy','sad','surprise','neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe87451",
   "metadata": {},
   "source": [
    "## fer2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc8c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_fer.copy( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e511c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35887, 3) 107661 Index(['emotion', 'pixels', 'Usage'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.shape, df.size, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f46c48c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_size=(48,48)\n",
    "pixels = df['pixels'].tolist() # Converting the relevant column element into a list for each row\n",
    "width, height = 48, 48\n",
    "faces = []\n",
    "\n",
    "for pixel_sequence in pixels:\n",
    "    face = [int(pixel) for pixel in pixel_sequence.split(' ')] # Splitting the string by space character as a list\n",
    "    face = np.asarray(face).reshape(width, height) #converting the list to numpy array in size of 48*48\n",
    "    face = cv2.resize(face.astype('uint8'),image_size) #resize the image to have 48 cols (width) and 48 rows (height)\n",
    "    faces.append(face.astype('float32')) #makes the list of each images of 48*48 and their pixels in numpyarray form\n",
    "\n",
    "faces = np.asarray(faces) #converting the list into numpy array\n",
    "faces = np.expand_dims(faces, -1) #Expand the shape of an array -1=last dimension => means color space\n",
    "emotions = pd.get_dummies(df['emotion']).to_numpy() #doing the one hot encoding type on emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4328d40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48, 1)\n",
      "(35887, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "print(faces[0].shape)\n",
    "print(faces.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a79e3af",
   "metadata": {},
   "source": [
    "### Standardize or Normalize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c815de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize (from 0 to 1)\n",
    "x = faces.astype('float32')\n",
    "x = x / 255.0\n",
    "\n",
    "# scale pixel value (from -1 to 1)\n",
    "x = x - 0.5\n",
    "x = x * 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb9e5e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "229e56e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "q,t = emotions.shape\n",
    "q = len(x)\n",
    "q_train = int((0.8) * q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a174700e",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "710fc5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "x_train = x[:q_train]\n",
    "y_train = emotions[:q_train]\n",
    "\n",
    "# Validation data\n",
    "x_val = x[q_train:]\n",
    "y_val = emotions[q_train:]\n",
    "\n",
    "data_train = (train_x, train_y)\n",
    "data_val = (val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4c2d009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "train_x.shape (pixels):  (28709, 48, 48, 1)\n",
      "\n",
      "\n",
      "train_y.shape: (labels):  (28709, 7)\n",
      "\n",
      "\n",
      "val_x.shape (pixels):  (7178, 48, 48, 1)\n",
      "\n",
      "\n",
      "val_y.shape: (labels):  (7178, 7)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "print('train_x.shape (pixels): ',train_x.shape)  # ==> 4 dims -  no of images , width , height , color\n",
    "print(\"\\n\")\n",
    "print('train_y.shape: (labels): ',train_y.shape)\n",
    "print(\"\\n\")\n",
    "print('val_x.shape (pixels): ',val_x.shape)\n",
    "print(\"\\n\")\n",
    "print('val_y.shape: (labels): ',val_y.shape)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3944cbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a263446",
   "metadata": {},
   "source": [
    "## from 2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3183f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOW REPO:\n",
    "    #https://pub.towardsai.net/step-by-step-guide-in-creating-your-own-emotion-recognition-system-b8aba98134c8\n",
    "    #https://github.com/Nabeel110/Emotion-Recognition\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importing tesnsorflow model libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.models import model_from_json,load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc928bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned_model\n",
    "def base_model():\n",
    "    model = Sequential()\n",
    "    input_shape = (48,48,1)\n",
    "    #1st convolution layer\n",
    "    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    #2nd convolution layer\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #3rd convolution layer\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(7))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    my_optimiser = tf.keras.optimizers.Adam(\n",
    "    learning_rate = 0.001, beta_1=0.9, beta_2=0.999, \n",
    "        epsilon=1e-07, amsgrad=False, name='Adam')\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'],\n",
    "                  optimizer=my_optimiser)\n",
    "    \n",
    "    print(model.summary)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f90320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f8c75cb37c0>>\n",
      "Epoch 1/15\n",
      " 15/575 [..............................] - ETA: 19:23 - loss: 2.4003 - accuracy: 0.1400"
     ]
    }
   ],
   "source": [
    "model_1 = base_model()\n",
    "\n",
    "model_1.fit(x_train, y_train, \n",
    "            validation_data=(x_val, y_val), \n",
    "            epochs=15,\n",
    "            verbose=1, \n",
    "            batch_size=50)\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eddfcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462de03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccf1e85c",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b83b415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iron",
   "language": "python",
   "name": "iron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
