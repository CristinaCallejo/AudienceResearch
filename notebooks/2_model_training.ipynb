{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1252b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importing tensorflow model libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.models import model_from_json,load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import *\n",
    "import tensorflow.keras.backend as K\n",
    "import json\n",
    "import time\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29431ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98c61343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/cris/Iron/AudienceResearch/models')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_dir = Path.cwd().parent/'models'\n",
    "mod_file = mod_dir/'model_v4red.hdf5'\n",
    "mod_file.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac20da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('model_v3.hdf5', 'r')\n",
    "model = h5py.File('model_v3.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "50e764a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "22b39d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transf_imported_Image(uploaded_file):\n",
    "    counter_faces = 0\n",
    "    img = Image.open(uploaded_file)\n",
    "    new = img.save(f\"demo/{counter_faces}.jpg\")\n",
    "\n",
    "    #input_img1 = cv2.imread(f\"demo/{counter_faces}.jpg\")\n",
    "    input_img1 = cv2.imread(new)\n",
    "    input_img2 = cv2.cvtColor(input_img1, cv2.COLOR_BGR2GRAY)\n",
    "    input_img3 = input_img2.copy()\n",
    "    face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    faces = face_cascade.detectMultiScale(input_img2, 1.25, 6)\n",
    "        \n",
    "    for (x,y,w,h) in faces:\n",
    "        \n",
    "        counter_faces += 1\n",
    "        img_data1 = input_img3 [y:y+h,x:x+w]\n",
    "        img_data2 = cv2.resize (img_data1, (48, 48))\n",
    "        img_data3 = np.stack(img_data2) \n",
    "        img_data4 = img_data2 / 255.0\n",
    "        img_data5 = np.expand_dims(\n",
    "            img_data4, axis=0).reshape(\n",
    "                np.expand_dims(\n",
    "                    img_data4, axis=0).shape[0], 48, 48, 1)\n",
    "        \n",
    "        cv2.imwrite(f\"demo/{counter_fotos}_{counter_faces}.jpg\", img_data2)\n",
    "        \n",
    "        img_datashow = img_data3*255\n",
    "        img_show = Image.fromarray(img_datashow)\n",
    "        img = Image.open(\"images_support/cover1.jpeg\")\n",
    "        img_show.save(f\"demo/{counter_fotos}_{counter_faces}_a.jpg\")\n",
    "            \n",
    "        arr_for_model = img_data5\n",
    "        counter_faces = 0\n",
    "        \n",
    "        print(\"terminado de proc\")\n",
    "        \n",
    "        return arr_for_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de08fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    try: \t\n",
    "        model_path = './models/model.h5'\n",
    "\t    model_weights_path = './models/weights/.h5'\n",
    "\"\"\"   \n",
    "def playingGod(happiness):\n",
    "    model = load_model()\n",
    "    \n",
    "    with open()\n",
    "    model.load_weights(weights_path)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    # Convert predictions classes to one hot vectors \n",
    "    Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "    # Convert validation observations to one hot vectors\n",
    "    print(Y_pred_classes)\n",
    "    Y_true = np.argmax(y_test,axis = 1)\n",
    "    print(Y_true)\n",
    "    # compute the confusion matrix\n",
    "    cm = confusion_matrix(Y_true, Y_pred_classes)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    # plot the confusion matrix\n",
    "    f,ax = plt.subplots(figsize=(8, 8))\n",
    "    sns.heatmap(cm, annot=True, linewidths=0.01,cmap=\"YlGnBu\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1388a0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "/Users/cris/Iron/AudienceResearch/src/haarcascade_frontalface_default.xml\n",
    "src/haarcascade_frontalface_default.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2929e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "being_happy = cc2.playingGod(model.predict(binary_emo)[0])\n",
    "\n",
    "        happiness = being_happy[0]\n",
    "        not_quite_so_much_happiness = being_happy[1]\n",
    "        \n",
    "        if being_happy[0] > 0.7:\n",
    "            st.write(\n",
    "                '''\n",
    "                There is a f\"{being_happy[0]}\" chance that this user is having a HAPPY experience!\n",
    "                ''')\n",
    "        else:\n",
    "            st.write(\n",
    "                '''\n",
    "                The image processed leaves some doubts, but here are the results:\n",
    "                there is a f\"{being_happy[0]}\" chance that the user \n",
    "                is having a good time vs f\"{being_happy[1]}\". \n",
    "                It might be time to take a step back and consider exploring \n",
    "                just how much tech has to offer in the industry:\n",
    "                your clients\n",
    "                your your product!\n",
    "                ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6e70b6f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'demo/0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-d7a42aae7a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransf_imported_Image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfotito\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-91d065fd907e>\u001b[0m in \u001b[0;36mtransf_imported_Image\u001b[0;34m(uploaded_file)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcounter_faces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"demo/{counter_faces}.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#input_img1 = cv2.imread(f\"demo/{counter_faces}.jpg\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2167\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2168\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2169\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2171\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'demo/0.jpg'"
     ]
    }
   ],
   "source": [
    "transf_imported_Image(fotito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0fadde80",
   "metadata": {},
   "outputs": [],
   "source": [
    "fotito = Path.home()/'Iron'/'AudienceResearch'/'demo'/'foto_aux1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b91d74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img=cv2.imread(str(fotito))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3acf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfImag2(path):\n",
    "\n",
    "    input_img=cv2.imread(path)\n",
    "    input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(input_img, 1.25, 6)\n",
    "    x,y,w,h = faces[0]\n",
    "    img_data= input_img[y:y+h,x:x+w]\n",
    "    img_data=cv2.resize(img_data,(48,48))\n",
    "    \n",
    "    img_data = np.stack(img_data)\n",
    "    img_data = img_data / 255.0\n",
    "    \n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dbd4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIC = transfImag2('foto.jpg') # transform pic\n",
    "input_img=cv2.imread('foto.jpg') # get the array of the original pic\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(input_img) # original pic\n",
    "plt.subplot(122)\n",
    "plt.imshow(Image.fromarray(PIC.squeeze()*255)) # transformed pic\n",
    "\n",
    "PIC = np.expand_dims(PIC,axis=0).reshape(np.expand_dims(PIC,axis=0).shape[0], 48, 48, 1)\n",
    "print(PIC.shape)\n",
    "pred2 = model_1.predict(PIC)[0]\n",
    "print(\"Probs -> happy:{0:.5f} unhappy:{1:.5f}\".format(pred2[0],pred2[1]))\n",
    "\n",
    "happy = pred2[0]\n",
    "unhappy = pred2[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iron",
   "language": "python",
   "name": "iron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
