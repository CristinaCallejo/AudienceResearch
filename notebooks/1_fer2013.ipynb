{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8644718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "#os.sys.path\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f890de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing tensorflow model libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.models import model_from_json,load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import *\n",
    "import tensorflow.keras.backend as K\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc2b27d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2855c31",
   "metadata": {},
   "source": [
    "### IMGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f90ec25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = Path.home()/'Iron'/'inp1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ad1a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = inp1/'TRAIN'\n",
    "train_imgs_haar = inp1/'TRAIN_haar'\n",
    "val_imgs = inp1/'VALIDATION'\n",
    "test_imgs = inp1/'TEST'\n",
    "demo_imgs = Path.cwd().parent/'demo'\n",
    "demo_imgs_faces = Path.cwd().parent/'demo_haar'\n",
    "demo_imgs_haar = Path.cwd().parent/'demo_faces'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e5ec535",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo1 = demo_imgs/'demooo_01.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25b2d8b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e5af9b3e747f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(df.shape, df.size, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "574c9e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo1.is_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91842018",
   "metadata": {},
   "source": [
    "### DATASETS to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7c61700",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fer = pd.read_csv(inp1/'Fer.csv',encoding = \"ISO-8859-1\")\n",
    "df_train = pd.read_csv(inp1/'Training_Data.csv',encoding = \"ISO-8859-1\")\n",
    "df_test = pd.read_csv(inp1/'Testing_Data.csv',encoding = \"ISO-8859-1\")\n",
    "df_val = pd.read_csv(inp1/'Validation_Data.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8901b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../src/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('../src/haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('../src/haarcascade_smile.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17785e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35887, 3) 107661 Index(['emotion', 'pixels', 'Usage'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = df_fer.copy()\n",
    "print(df.shape, df.size, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd00ecac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 6, 3, 5, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.emotion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "898015d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emos = {0:'Angry',1: 'Disgust',2:'Fear',3:'Happy',4:'Sad',5:'Surprise',6:'Neutral'}\n",
    "#df['emos'] = df.emotion.map(emos)\n",
    "df['emotion_names'] = df.emotion.map(emos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d907672",
   "metadata": {},
   "outputs": [],
   "source": [
    "emos2 = {0:'unhappy', 1:'unhappy',2:'unhappy',3:'happy',4:'unhappy',5:'unhappy',6:'unhappy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2329ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emo'] = df.emotion.map(emos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf102a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = pd.get_dummies(df['emo']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a864a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.get_dummies(df, columns = ['emo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f55d9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "      <th>emotion_names</th>\n",
       "      <th>emo_happy</th>\n",
       "      <th>emo_unhappy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Angry</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Angry</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Sad</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage  \\\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training   \n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training   \n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training   \n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training   \n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training   \n",
       "\n",
       "  emotion_names  emo_happy  emo_unhappy  \n",
       "0         Angry          0            1  \n",
       "1         Angry          0            1  \n",
       "2          Fear          0            1  \n",
       "3           Sad          0            1  \n",
       "4       Neutral          0            1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76a5cf34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training       28709\n",
       "PrivateTest     3589\n",
       "PublicTest      3589\n",
       "Name: Usage, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.Usage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e1d0689",
   "metadata": {},
   "outputs": [],
   "source": [
    "drpp = ['emotion', 'Usage']\n",
    "df3 = df2.drop(drpp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0edf5d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth1 = Path.cwd().parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "edc57d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/cris/Iron')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c83d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth2 = Path.home()/'Iron'/'data_processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61ec1386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/cris/Iron/data_processed')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6da86b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(str(pth2/'df_fer_one.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92cc44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "164c2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['pixar1'] = [[float(x) for x in each.split()] for each in df4['pixels']]\n",
    "df4['pixar2'] = df4['pixar1'].apply(lambda x: np.asarray(x).reshape(48,48)).apply(lambda x:x.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ccaeb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['emo_arr1'] = df4.pixar2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "544420f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixels</th>\n",
       "      <th>emotion_names</th>\n",
       "      <th>emo_happy</th>\n",
       "      <th>emo_unhappy</th>\n",
       "      <th>pixar1</th>\n",
       "      <th>pixar2</th>\n",
       "      <th>emo_arr1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Angry</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63....</td>\n",
       "      <td>[[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...</td>\n",
       "      <td>[[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Angry</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 111...</td>\n",
       "      <td>[[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...</td>\n",
       "      <td>[[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 161...</td>\n",
       "      <td>[[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 16...</td>\n",
       "      <td>[[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20....</td>\n",
       "      <td>[[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20...</td>\n",
       "      <td>[[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              pixels emotion_names  emo_happy  \\\n",
       "0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...         Angry          0   \n",
       "1  151 150 147 155 148 133 111 140 170 174 182 15...         Angry          0   \n",
       "2  231 212 156 164 174 138 161 173 182 200 106 38...          Fear          0   \n",
       "3  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...           Sad          0   \n",
       "4  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...       Neutral          0   \n",
       "\n",
       "   emo_unhappy                                             pixar1  \\\n",
       "0            1  [70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63....   \n",
       "1            1  [151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 111...   \n",
       "2            1  [231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 161...   \n",
       "3            1  [24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20....   \n",
       "4            1  [4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                              pixar2  \\\n",
       "0  [[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...   \n",
       "1  [[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...   \n",
       "2  [[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 16...   \n",
       "3  [[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20...   \n",
       "4  [[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                            emo_arr1  \n",
       "0  [[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...  \n",
       "1  [[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...  \n",
       "2  [[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 16...  \n",
       "3  [[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20...  \n",
       "4  [[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b438b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/pandas/core/series.py\", line 4138, in apply\n",
      "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
      "  File \"pandas/_libs/lib.pyx\", line 2467, in pandas._libs.lib.map_infer\n",
      "  File \"<ipython-input-49-766c9390d2b0>\", line 1, in <lambda>\n",
      "    df4['emo_arr'] = df4['emo_arr1'].apply(lambda x: np.array([[[c] for c in i] for i in x]))\n",
      "  File \"<ipython-input-49-766c9390d2b0>\", line 1, in <listcomp>\n",
      "    df4['emo_arr'] = df4['emo_arr1'].apply(lambda x: np.array([[[c] for c in i] for i in x]))\n",
      "  File \"<ipython-input-49-766c9390d2b0>\", line 1, in <listcomp>\n",
      "    df4['emo_arr'] = df4['emo_arr1'].apply(lambda x: np.array([[[c] for c in i] for i in x]))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-49-766c9390d2b0>\", line 1, in <module>\n",
      "    df4['emo_arr'] = df4['emo_arr1'].apply(lambda x: np.array([[[c] for c in i] for i in x]))\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/pandas/core/series.py\", line 4138, in apply\n",
      "    mapped = lib.map_infer(values, f, convert=convert_dtype)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/inspect.py\", line 1465, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 182, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/linecache.py\", line 137, in updatecache\n",
      "    lines = fp.readlines()\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/codecs.py\", line 319, in decode\n",
      "    def decode(self, input, final=False):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4138\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-766c9390d2b0>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emo_arr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emo_arr1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-766c9390d2b0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emo_arr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emo_arr1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-766c9390d2b0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emo_arr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emo_arr1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-766c9390d2b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emo_arr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emo_arr1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4138\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2046\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2047\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1436\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1193\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "df4['emo_arr'] = df4['emo_arr1'].apply(lambda x: np.array([[[c] for c in i] for i in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d194c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df5 = df4.rename(columns={'emotion_yn_happy': 'emo_happy','emotion_yn_unhappy':'emo_unhappy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01dc382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9188950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc1be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.to_csv(str(pth2/'df_fer_v3.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bbe9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['dums'] = df5[['emo_happy','emo_unhappy']].apply(lambda x: pd.Series([x.values]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a4b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b29c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "drpp = ['pixar1','pixar2']\n",
    "df5.drop(columns = drpp, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce4009",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = df5['pixels']\n",
    "df5.drop(labels=['pixels'], axis=1, inplace = True)\n",
    "df5.insert(3, 'pixels', mid)\n",
    "df5.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cbfc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.to_csv(str(pth2/'df_fer_three.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5239d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef4fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = (np.stack(df5['emo_arr'])) / 255.0\n",
    "y1 = np.stack(df5.dums)\n",
    "X1.shape, y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ff199",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_testval, y1_train, y1_testval = train_test_split(X1,y1,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test, X1_val, y1_test, y1_val = train_test_split(X1_testval,y1_testval,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f537d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c476421",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc386ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90cc894",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c8896",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867fdb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a749d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0feb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test.shape, X1_val.shape, y1_test.shape, y1_val.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9519e6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b92a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cbb472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f471efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test, X1_val, y1_test, y1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c89f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split(X_testval,y_testval,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5fe0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80348c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c0dfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57aaf90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfImag(path, new_path):\n",
    "    \n",
    "    # ROCKET\n",
    "    \"\"\"\n",
    "    recibe carpeta, en cada foto de esa carpeta:\n",
    "    lectura\n",
    "    to gray\n",
    "    facecascade\n",
    "    por xywh en cada cara:\n",
    "        array\n",
    "        reshape array a 2d\n",
    "        stack array 3d\n",
    "        normalizar\n",
    "        expand 4d\n",
    "    devuelve array x cada foto para pasarselo al modelo\n",
    "    \"\"\"\n",
    "    counter_imgs = 0\n",
    "    counter_faces = 0\n",
    "    \n",
    "    X_ = pd.Series([], dtype='float64')\n",
    "    \n",
    "    for file in sorted(path.iterdir()):\n",
    "        \n",
    "        counter_imgs += 1\n",
    "\n",
    "        input_img1 = cv2.imread(str(file))\n",
    "        input_img2 = cv2.cvtColor(input_img1, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(input_img2, 1.25, 6)\n",
    "        \n",
    "        for (x,y,w,h) in faces:\n",
    "            \n",
    "            counter_faces += 1\n",
    "            img_data1 = input_img2 [y:y+h,x:x+w]\n",
    "            img_data2 = cv2.resize (img_data1,(48,48))\n",
    "\n",
    "            img_data3 = np.stack(img_data2) \n",
    "            img_data4 = img_data2 / 255.0\n",
    "            img_data5 = img_data3 / 255.0\n",
    "            \n",
    "            img_data6 = np.expand_dims(img_data5,axis=0).reshape(np.expand_dims(img_data5,axis=0).shape[0], 48, 48, 1)\n",
    "            \n",
    "            print(img_data6.shape)\n",
    "            print(img_data6)\n",
    "            \n",
    "            img_datashow = img_data3*255\n",
    "            img_show = Image.fromarray(img_datashow)\n",
    "            file_to_save = file.name.replace(\".\",f\"_face{counter_faces}.\")\n",
    "            img_show.save(str(new_path/file_to_save))\n",
    "            \n",
    "            counter_faces = 0\n",
    "            \n",
    "            arr_for_model = img_data6\n",
    "            \n",
    "            \n",
    "            return arr_for_model\n",
    "    \n",
    "    print('YAAA!')    \n",
    "    return counter_imgs\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5307b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    input_shape = (48,48,1)\n",
    "    #1st convolution layer\n",
    "    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    #2nd convolution layer\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #3rd convolution layer\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(7))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    my_optimiser = tf.keras.optimizers.Adam(\n",
    "    learning_rate = 0.001, beta_1=0.9, beta_2=0.999, \n",
    "        epsilon=1e-07, amsgrad=False, name='Adam')\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'],\n",
    "                  optimizer=my_optimiser)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693777ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "361cd185",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X1_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3294966fd20d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model_1.fit(X1_train, y1_train, \n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X1_train' is not defined"
     ]
    }
   ],
   "source": [
    "model_1 = base_model()\n",
    "\n",
    "model_1.fit(X1_train, y1_train, \n",
    "            validation_data=(X1_val, y1_val), \n",
    "            epochs=15,\n",
    "            verbose=1, \n",
    "            batch_size=50)\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e70d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70718ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ea588",
   "metadata": {},
   "outputs": [],
   "source": [
    "impotd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0be2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfImag(demo_imgs, demo_imgs_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f64bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a565e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2725a6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8ef48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48561131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fd4286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e61bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAAR CASCADE CLASSIFIER\n",
    "def detect_face_eyes_smile(pth,new_pth):\n",
    "    \"\"\"\n",
    "    Extracts all .jpg files from local path, \n",
    "    calls on haar cascade classifiers (frontalface, eyes and smile) \n",
    "    and draws detection rectangles on each .jpg \n",
    "    \n",
    "    Takes: local path of directory with .jpg images\n",
    "    \n",
    "    Returns: individual windows for .jpg files with detection rectangles for face, eyes and smile\n",
    "    \"\"\"\n",
    "\n",
    "    counter_imgs = 0\n",
    "    counter_faces = 0\n",
    "    counter_smiles = 0\n",
    "    counter_eyes = 0\n",
    "    face_cascade = cv2.CascadeClassifier('../src/haarcascade_frontalface_default.xml')\n",
    "    eye_cascade = cv2.CascadeClassifier('../src/haarcascade_eye.xml')\n",
    "    smile_cascade = cv2.CascadeClassifier('../src/haarcascade_smile.xml')\n",
    "    \n",
    "    for file in sorted(pth.iterdir()):\n",
    "        if file.suffix != '.jpg':\n",
    "            pass\n",
    "        else:\n",
    "            counter_imgs += 1\n",
    "            print(file.name)\n",
    "            \n",
    "            img = cv2.imread(str(file))\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            #plt.imshow(img)\n",
    "\n",
    "            # FRONTAL FACE \n",
    "            \n",
    "            faces = face_cascade.detectMultiScale(\n",
    "                img_gray, \n",
    "                scaleFactor=1.06,                \n",
    "                minNeighbors=7,\n",
    "                minSize=(30, 30), \n",
    "                flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "            if faces is None:\n",
    "                print(\"No Face Found\")\n",
    "\n",
    "            for (fx,fy,fw,fh) in faces:\n",
    "                \n",
    "                counter_faces += 1\n",
    "                roi_gray = img_gray [fy:fy+fh, fx:fx+fw] # region of interest for detection\n",
    "                roi_gray2 = cv2.resize (roi_gray, (48,48))\n",
    "                roi_gray3 = np.stack(roi_gray2)\n",
    "                roi_gray4 = roi_gray2 / 255\n",
    "                \n",
    "                roi_color = img[fy:fy+fh, fx:fx+fw] # region of interest for mapping rectangle\n",
    "                roi_color2 = cv2.resize (roi_color, (48,48))\n",
    "                roi_color3 = np.stack(roi_color2)\n",
    "                roi_color4 = roi_color2 / 255\n",
    "                \n",
    "                cv2.rectangle(\n",
    "                    img,\n",
    "                    (fx,fy),\n",
    "                    (fx+fw,fy+fh),\n",
    "                    #(127,0,255),\n",
    "                    (0,255,0),\n",
    "                    2)\n",
    "\n",
    "                # SMILES \n",
    "\n",
    "                smiles = smile_cascade.detectMultiScale(\n",
    "                    roi_gray, \n",
    "                    scaleFactor = 1.35, \n",
    "                    minNeighbors = 8)\n",
    "\n",
    "                for (sx, sy, sw, sh) in smiles:\n",
    "                    counter_smiles += 1\n",
    "                    cv2.rectangle(\n",
    "                        roi_color,\n",
    "                        (sx, sy),\n",
    "                        (sx + sw, sy + sh),\n",
    "                        #(255, 0, 130),\n",
    "                        #(0,220,80),\n",
    "                        (127,0,255),\n",
    "                        1)\n",
    "\n",
    "                # EYES\n",
    "\n",
    "                eyes = eye_cascade.detectMultiScale(\n",
    "                    roi_gray,\n",
    "                    scaleFactor=1.05,\n",
    "                    minNeighbors = 6)\n",
    "\n",
    "                for (ex,ey,ew,eh) in eyes:\n",
    "                    counter_eyes += 1\n",
    "                    cv2.rectangle(\n",
    "                        roi_color, \n",
    "                        (ex , ey),\n",
    "                        (ex + ew, ey + eh),\n",
    "                        (0,255,255),\n",
    "                        1)\n",
    "            \n",
    "                # save images with detected regions\n",
    "                file_to_save = file.name.replace(\".\",f\"_face{counter_faces}.\")\n",
    "                \n",
    "                #cv2.imwrite(str(pth.parent/'demo_faces'/file_to_save),img)\n",
    "                cv2.imwrite(str(new_pth/file_to_save),roi_color)\n",
    "                counter_imgs = 0\n",
    "                counter_faces = 0\n",
    "            # show the output frame\n",
    "            cv2.imshow(f\"img{file_to_save}\", img)\n",
    "            key = cv2.waitKey(100) & 0xFF\n",
    "            \n",
    "    cv2.destroyAllWindows(f\"img{file_to_save}\")\n",
    "    \n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "            if key == ord(\"q\"):\n",
    "                # do a bit of cleanup\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "        \n",
    "    # do a bit of cleanup\n",
    "    cv2.destroyAllWindows()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168dd7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_imgs = Path.cwd().parent/'demo'\n",
    "demo_imgs_faces = Path.cwd().parent/demo2\n",
    "demo1 = demo_imgs/'A_0.jpg'\n",
    "demo2 = demo_imgs/'demooo_01.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3705e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../src/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('../src/haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('../src/haarcascade_smile.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb5cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b7b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fc56ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd40eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(str(pth.parent/*'_haar'/file.name),roi_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(pth.parent/'*_haar'/file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef1dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iron",
   "language": "python",
   "name": "iron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
