{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "077d8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "#os.sys.path\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "92c1b749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing tensorflow model libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.models import model_from_json,load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import *\n",
    "import tensorflow.keras.backend as K\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594e7385",
   "metadata": {},
   "source": [
    "### IMGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "87a3976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = Path.home()/'Iron'/'inp1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b48ae792",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = inp1/'TRAIN'\n",
    "train_imgs_haar = inp1/'TRAIN_haar'\n",
    "val_imgs = inp1/'VALIDATION'\n",
    "test_imgs = inp1/'TEST'\n",
    "demo_imgs = Path.cwd().parent/'demo'\n",
    "demo_imgs_faces = Path.cwd().parent/'demo_haar'\n",
    "demo_imgs_haar = Path.cwd().parent/'demo_faces'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0079d7b3",
   "metadata": {},
   "source": [
    "### DATASETS to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5ec287e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fer = pd.read_csv(inp1/'Fer.csv',encoding = \"ISO-8859-1\")\n",
    "df_train = pd.read_csv(inp1/'Training_Data.csv',encoding = \"ISO-8859-1\")\n",
    "df_test = pd.read_csv(inp1/'Testing_Data.csv',encoding = \"ISO-8859-1\")\n",
    "df_val = pd.read_csv(inp1/'Validation_Data.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "79ab3fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../src/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('../src/haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('../src/haarcascade_smile.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2f139b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c52be791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfImag(path, new_path):\n",
    "    \"\"\"\n",
    "    recibe carpeta, en cada foto de esa carpeta:\n",
    "    lectura\n",
    "    to gray\n",
    "    facecascade\n",
    "    por xywh en cada cara:\n",
    "        array\n",
    "        reshape array a 2d\n",
    "        stack array 3d\n",
    "        normalizar\n",
    "        expand 4d\n",
    "    devuelve array x cada foto para pasarselo al modelo\n",
    "    \"\"\"\n",
    "    counter_imgs = 0\n",
    "    counter_faces = 0\n",
    "    \n",
    "    for file in sorted(path.iterdir()):\n",
    "        \n",
    "        counter_imgs += 1\n",
    "\n",
    "        input_img1 = cv2.imread(str(file))\n",
    "        input_img2 = cv2.cvtColor(input_img1, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(input_img2, 1.25, 6)\n",
    "        \n",
    "        for (x,y,w,h) in faces:\n",
    "            \n",
    "            counter_faces += 1\n",
    "            img_data1 = input_img2 [y:y+h,x:x+w]\n",
    "            img_data2 = cv2.resize (img_data1,(48,48))\n",
    "\n",
    "            img_data3 = np.stack(img_data2) \n",
    "            img_data4 = img_data2 / 255.0\n",
    "            img_data5 = img_data3 / 255.0\n",
    "            \n",
    "            img_data6 = np.expand_dims(img_data5,axis=0).reshape(np.expand_dims(img_data5,axis=0).shape[0], 48, 48, 1)\n",
    "            \n",
    "            print(img_data6.shape)\n",
    "            \n",
    "            img_datashow = img_data3*255\n",
    "            \n",
    "            img_show = Image.fromarray(img_datashow)\n",
    "            \n",
    "            file_to_save = file.name.replace(\".\",f\"_face{counter_faces}.\")\n",
    "            \n",
    "            img_show.save(str(new_path/file_to_save))\n",
    "            \n",
    "            counter_faces = 0\n",
    "            \n",
    "            arr_for_model = img_data6\n",
    "            \n",
    "            \n",
    "            return arr_for_model\n",
    "    \n",
    "    print('YAAA!')    \n",
    "    return counter_imgs\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1044f8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 48, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[0.26666667],\n",
       "         [0.41568627],\n",
       "         [0.29803922],\n",
       "         ...,\n",
       "         [0.36862745],\n",
       "         [0.37254902],\n",
       "         [0.36078431]],\n",
       "\n",
       "        [[0.2745098 ],\n",
       "         [0.23137255],\n",
       "         [0.25098039],\n",
       "         ...,\n",
       "         [0.35294118],\n",
       "         [0.33333333],\n",
       "         [0.34117647]],\n",
       "\n",
       "        [[0.2745098 ],\n",
       "         [0.28627451],\n",
       "         [0.1372549 ],\n",
       "         ...,\n",
       "         [0.35294118],\n",
       "         [0.34901961],\n",
       "         [0.37254902]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00392157],\n",
       "         [0.05882353],\n",
       "         [0.10980392],\n",
       "         ...,\n",
       "         [0.22745098],\n",
       "         [0.25490196],\n",
       "         [0.12156863]],\n",
       "\n",
       "        [[0.00392157],\n",
       "         [0.06666667],\n",
       "         [0.13333333],\n",
       "         ...,\n",
       "         [0.28627451],\n",
       "         [0.11372549],\n",
       "         [0.06666667]],\n",
       "\n",
       "        [[0.00392157],\n",
       "         [0.06666667],\n",
       "         [0.14509804],\n",
       "         ...,\n",
       "         [0.25490196],\n",
       "         [0.16862745],\n",
       "         [0.15686275]]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfImag(demo_imgs, demo_imgs_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    input_shape = (48,48,1)\n",
    "    #1st convolution layer\n",
    "    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    #2nd convolution layer\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #3rd convolution layer\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(7))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    my_optimiser = tf.keras.optimizers.Adam(\n",
    "    learning_rate = 0.001, beta_1=0.9, beta_2=0.999, \n",
    "        epsilon=1e-07, amsgrad=False, name='Adam')\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'],\n",
    "                  optimizer=my_optimiser)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fed3bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = base_model()\n",
    "\n",
    "model_v1 = model_1.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=15,\n",
    "            verbose=1, \n",
    "            batch_size=50)\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f2b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d9e067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e039b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d09e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee908e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b93569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a7874a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAAR CASCADE CLASSIFIER\n",
    "def detect_face_eyes_smile(pth,new_pth):\n",
    "    \"\"\"\n",
    "    Extracts all .jpg files from local path, \n",
    "    calls on haar cascade classifiers (frontalface, eyes and smile) \n",
    "    and draws detection rectangles on each .jpg \n",
    "    \n",
    "    Takes: local path of directory with .jpg images\n",
    "    \n",
    "    Returns: individual windows for .jpg files with detection rectangles for face, eyes and smile\n",
    "    \"\"\"\n",
    "\n",
    "    counter_imgs = 0\n",
    "    counter_faces = 0\n",
    "    counter_smiles = 0\n",
    "    counter_eyes = 0\n",
    "    face_cascade = cv2.CascadeClassifier('../src/haarcascade_frontalface_default.xml')\n",
    "    eye_cascade = cv2.CascadeClassifier('../src/haarcascade_eye.xml')\n",
    "    smile_cascade = cv2.CascadeClassifier('../src/haarcascade_smile.xml')\n",
    "    \n",
    "    for file in sorted(pth.iterdir()):\n",
    "        if file.suffix != '.jpg':\n",
    "            pass\n",
    "        else:\n",
    "            counter_imgs += 1\n",
    "            print(file.name)\n",
    "            \n",
    "            img = cv2.imread(str(file))\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            #plt.imshow(img)\n",
    "\n",
    "            # FRONTAL FACE \n",
    "            \n",
    "            faces = face_cascade.detectMultiScale(\n",
    "                img_gray, \n",
    "                scaleFactor=1.06,                \n",
    "                minNeighbors=7,\n",
    "                minSize=(30, 30), \n",
    "                flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "            if faces is None:\n",
    "                print(\"No Face Found\")\n",
    "\n",
    "            for (fx,fy,fw,fh) in faces:\n",
    "                \n",
    "                counter_faces += 1\n",
    "                roi_gray = img_gray [fy:fy+fh, fx:fx+fw] # region of interest for detection\n",
    "                roi_gray2 = cv2.resize (roi_gray, (48,48))\n",
    "                roi_gray3 = np.stack(roi_gray2)\n",
    "                roi_gray4 = roi_gray2 / 255\n",
    "                \n",
    "                roi_color = img[fy:fy+fh, fx:fx+fw] # region of interest for mapping rectangle\n",
    "                roi_color2 = cv2.resize (roi_color, (48,48))\n",
    "                roi_color3 = np.stack(roi_color2)\n",
    "                roi_color4 = roi_color2 / 255\n",
    "                \n",
    "                cv2.rectangle(\n",
    "                    img,\n",
    "                    (fx,fy),\n",
    "                    (fx+fw,fy+fh),\n",
    "                    #(127,0,255),\n",
    "                    (0,255,0),\n",
    "                    2)\n",
    "\n",
    "                # SMILES \n",
    "\n",
    "                smiles = smile_cascade.detectMultiScale(\n",
    "                    roi_gray, \n",
    "                    scaleFactor = 1.35, \n",
    "                    minNeighbors = 8)\n",
    "\n",
    "                for (sx, sy, sw, sh) in smiles:\n",
    "                    counter_smiles += 1\n",
    "                    cv2.rectangle(\n",
    "                        roi_color,\n",
    "                        (sx, sy),\n",
    "                        (sx + sw, sy + sh),\n",
    "                        #(255, 0, 130),\n",
    "                        #(0,220,80),\n",
    "                        (127,0,255),\n",
    "                        1)\n",
    "\n",
    "                # EYES\n",
    "\n",
    "                eyes = eye_cascade.detectMultiScale(\n",
    "                    roi_gray,\n",
    "                    scaleFactor=1.05,\n",
    "                    minNeighbors = 6)\n",
    "\n",
    "                for (ex,ey,ew,eh) in eyes:\n",
    "                    counter_eyes += 1\n",
    "                    cv2.rectangle(\n",
    "                        roi_color, \n",
    "                        (ex , ey),\n",
    "                        (ex + ew, ey + eh),\n",
    "                        (0,255,255),\n",
    "                        1)\n",
    "            \n",
    "                # save images with detected regions\n",
    "                file_to_save = file.name.replace(\".\",f\"_face{counter_faces}.\")\n",
    "                \n",
    "                #cv2.imwrite(str(pth.parent/'demo_faces'/file_to_save),img)\n",
    "                cv2.imwrite(str(new_pth/file_to_save),roi_color)\n",
    "                counter_imgs = 0\n",
    "                counter_faces = 0\n",
    "            # show the output frame\n",
    "            cv2.imshow(f\"img{file_to_save}\", img)\n",
    "            key = cv2.waitKey(100) & 0xFF\n",
    "            \n",
    "    cv2.destroyAllWindows(f\"img{file_to_save}\")\n",
    "    \n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "            if key == ord(\"q\"):\n",
    "                # do a bit of cleanup\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "        \n",
    "    # do a bit of cleanup\n",
    "    cv2.destroyAllWindows()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94447c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_imgs = Path.cwd().parent/'demo'\n",
    "demo_imgs_faces = Path.cwd().parent/demo2\n",
    "demo1 = demo_imgs/'A_0.jpg'\n",
    "demo2 = demo_imgs/'demooo_01.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1abed1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../src/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('../src/haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('../src/haarcascade_smile.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cc5521f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e721c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17734d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1654f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(str(pth.parent/*'_haar'/file.name),roi_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d49fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(pth.parent/'*_haar'/file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b59757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iron",
   "language": "python",
   "name": "iron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
