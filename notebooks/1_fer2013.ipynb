{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8644718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "#os.sys.path\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f890de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing tensorflow model libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.models import model_from_json,load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import *\n",
    "import tensorflow.keras.backend as K\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc2b27d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2855c31",
   "metadata": {},
   "source": [
    "### IMGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90ec25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = Path.home()/'Iron'/'inp1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ad1a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = inp1/'TRAIN'\n",
    "train_imgs_haar = inp1/'TRAIN_haar'\n",
    "val_imgs = inp1/'VALIDATION'\n",
    "test_imgs = inp1/'TEST'\n",
    "demo_imgs = Path.cwd().parent/'demo'\n",
    "demo_imgs_faces = Path.cwd().parent/'demo_haar'\n",
    "demo_imgs_haar = Path.cwd().parent/'demo_faces'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91842018",
   "metadata": {},
   "source": [
    "### DATASETS to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbdfce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fer_ok --> sin dummies\n",
    "# df_fer_top --> con dummies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7c61700",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fer = pd.read_csv(inp1/'Fer.csv',encoding = \"ISO-8859-1\")\n",
    "df_train = pd.read_csv(inp1/'Training_Data.csv',encoding = \"ISO-8859-1\")\n",
    "df_test = pd.read_csv(inp1/'Testing_Data.csv',encoding = \"ISO-8859-1\")\n",
    "df_val = pd.read_csv(inp1/'Validation_Data.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8901b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../src/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('../src/haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('../src/haarcascade_smile.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17785e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35887, 3) 107661 Index(['emotion', 'pixels', 'Usage'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = df_fer.copy()\n",
    "print(df.shape, df.size, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd00ecac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 6, 3, 5, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.emotion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "898015d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emos = {0:'Angry',1: 'Disgust',2:'Fear',3:'Happy',4:'Sad',5:'Surprise',6:'Neutral'}\n",
    "#df['emos'] = df.emotion.map(emos)\n",
    "df['emotion_names'] = df.emotion.map(emos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d907672",
   "metadata": {},
   "outputs": [],
   "source": [
    "emos2 = {0:'unhappy', 1:'unhappy',2:'unhappy',3:'happy',4:'unhappy',5:'unhappy',6:'unhappy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2329ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emo'] = df.emotion.map(emos2).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "485a1b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "      <th>emotion_names</th>\n",
       "      <th>emo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Angry</td>\n",
       "      <td>unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Angry</td>\n",
       "      <td>unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Fear</td>\n",
       "      <td>unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Sad</td>\n",
       "      <td>unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>unhappy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage  \\\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training   \n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training   \n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training   \n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training   \n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training   \n",
       "\n",
       "  emotion_names      emo  \n",
       "0         Angry  unhappy  \n",
       "1         Angry  unhappy  \n",
       "2          Fear  unhappy  \n",
       "3           Sad  unhappy  \n",
       "4       Neutral  unhappy  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69997e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo = pd.get_dummies(df['emo']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "164c81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.get_dummies(df['emotion']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f55d9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "      <th>emotion_names</th>\n",
       "      <th>emo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Angry</td>\n",
       "      <td>unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Angry</td>\n",
       "      <td>unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Fear</td>\n",
       "      <td>unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Sad</td>\n",
       "      <td>unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35882</th>\n",
       "      <td>6</td>\n",
       "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35883</th>\n",
       "      <td>3</td>\n",
       "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>Happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>0</td>\n",
       "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>Angry</td>\n",
       "      <td>unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35885</th>\n",
       "      <td>3</td>\n",
       "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>Happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35886</th>\n",
       "      <td>2</td>\n",
       "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
       "      <td>PrivateTest</td>\n",
       "      <td>Fear</td>\n",
       "      <td>unhappy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35887 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion                                             pixels  \\\n",
       "0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...   \n",
       "1            0  151 150 147 155 148 133 111 140 170 174 182 15...   \n",
       "2            2  231 212 156 164 174 138 161 173 182 200 106 38...   \n",
       "3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...   \n",
       "4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...   \n",
       "...        ...                                                ...   \n",
       "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...   \n",
       "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...   \n",
       "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...   \n",
       "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...   \n",
       "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...   \n",
       "\n",
       "             Usage emotion_names      emo  \n",
       "0         Training         Angry  unhappy  \n",
       "1         Training         Angry  unhappy  \n",
       "2         Training          Fear  unhappy  \n",
       "3         Training           Sad  unhappy  \n",
       "4         Training       Neutral  unhappy  \n",
       "...            ...           ...      ...  \n",
       "35882  PrivateTest       Neutral  unhappy  \n",
       "35883  PrivateTest         Happy    happy  \n",
       "35884  PrivateTest         Angry  unhappy  \n",
       "35885  PrivateTest         Happy    happy  \n",
       "35886  PrivateTest          Fear  unhappy  \n",
       "\n",
       "[35887 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76a5cf34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['emotion', 'pixels', 'Usage', 'emotion_names', 'emo'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e1d0689",
   "metadata": {},
   "outputs": [],
   "source": [
    "drpp = ['emotion', 'Usage']\n",
    "df2 = df.drop(drpp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0edf5d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth1 = Path.cwd().parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c83d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth2 = Path.home()/'Iron'/'data_processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6da86b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(str(pth2/'df_fer_a.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92cc44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "164c2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['pixar1'] = [[float(x) for x in each.split()] for each in df3['pixels']]\n",
    "df3['pixar2'] = df3['pixar1'].apply(lambda x: np.asarray(x).reshape(48,48)).apply(lambda x:x.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccaeb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['emo_arr1'] = df3.pixar2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b438b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['emo_arr'] = df3['emo_arr1'].apply(lambda x: np.array([[[c] for c in i] for i in x])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f01dc382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9188950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixels</th>\n",
       "      <th>emotion_names</th>\n",
       "      <th>emo</th>\n",
       "      <th>pixar1</th>\n",
       "      <th>pixar2</th>\n",
       "      <th>emo_arr1</th>\n",
       "      <th>emo_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Angry</td>\n",
       "      <td>unhappy</td>\n",
       "      <td>[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63....</td>\n",
       "      <td>[[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...</td>\n",
       "      <td>[[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...</td>\n",
       "      <td>[[[70.0], [80.0], [82.0], [72.0], [58.0], [58....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Angry</td>\n",
       "      <td>unhappy</td>\n",
       "      <td>[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 111...</td>\n",
       "      <td>[[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...</td>\n",
       "      <td>[[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...</td>\n",
       "      <td>[[[151.0], [150.0], [147.0], [155.0], [148.0],...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              pixels emotion_names      emo  \\\n",
       "0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...         Angry  unhappy   \n",
       "1  151 150 147 155 148 133 111 140 170 174 182 15...         Angry  unhappy   \n",
       "\n",
       "                                              pixar1  \\\n",
       "0  [70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63....   \n",
       "1  [151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 111...   \n",
       "\n",
       "                                              pixar2  \\\n",
       "0  [[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...   \n",
       "1  [[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...   \n",
       "\n",
       "                                            emo_arr1  \\\n",
       "0  [[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...   \n",
       "1  [[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...   \n",
       "\n",
       "                                             emo_arr  \n",
       "0  [[[70.0], [80.0], [82.0], [72.0], [58.0], [58....  \n",
       "1  [[[151.0], [150.0], [147.0], [155.0], [148.0],...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfc1be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.to_csv(pth2/'df_fer_ok.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5bbe9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixels</th>\n",
       "      <th>emotion_names</th>\n",
       "      <th>emo</th>\n",
       "      <th>pixar1</th>\n",
       "      <th>pixar2</th>\n",
       "      <th>emo_arr1</th>\n",
       "      <th>emo_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Angry</td>\n",
       "      <td>unhappy</td>\n",
       "      <td>[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63....</td>\n",
       "      <td>[[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...</td>\n",
       "      <td>[[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...</td>\n",
       "      <td>[[[70.0], [80.0], [82.0], [72.0], [58.0], [58....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Angry</td>\n",
       "      <td>unhappy</td>\n",
       "      <td>[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 111...</td>\n",
       "      <td>[[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...</td>\n",
       "      <td>[[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...</td>\n",
       "      <td>[[[151.0], [150.0], [147.0], [155.0], [148.0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Fear</td>\n",
       "      <td>unhappy</td>\n",
       "      <td>[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 161...</td>\n",
       "      <td>[[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 16...</td>\n",
       "      <td>[[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 16...</td>\n",
       "      <td>[[[231.0], [212.0], [156.0], [164.0], [174.0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>unhappy</td>\n",
       "      <td>[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20....</td>\n",
       "      <td>[[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20...</td>\n",
       "      <td>[[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20...</td>\n",
       "      <td>[[[24.0], [32.0], [36.0], [30.0], [32.0], [23....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>unhappy</td>\n",
       "      <td>[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[[4.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              pixels emotion_names      emo  \\\n",
       "0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...         Angry  unhappy   \n",
       "1  151 150 147 155 148 133 111 140 170 174 182 15...         Angry  unhappy   \n",
       "2  231 212 156 164 174 138 161 173 182 200 106 38...          Fear  unhappy   \n",
       "3  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...           Sad  unhappy   \n",
       "4  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...       Neutral  unhappy   \n",
       "\n",
       "                                              pixar1  \\\n",
       "0  [70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63....   \n",
       "1  [151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 111...   \n",
       "2  [231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 161...   \n",
       "3  [24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20....   \n",
       "4  [4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                              pixar2  \\\n",
       "0  [[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...   \n",
       "1  [[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...   \n",
       "2  [[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 16...   \n",
       "3  [[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20...   \n",
       "4  [[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                            emo_arr1  \\\n",
       "0  [[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...   \n",
       "1  [[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...   \n",
       "2  [[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 16...   \n",
       "3  [[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20...   \n",
       "4  [[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                             emo_arr  \n",
       "0  [[[70.0], [80.0], [82.0], [72.0], [58.0], [58....  \n",
       "1  [[[151.0], [150.0], [147.0], [155.0], [148.0],...  \n",
       "2  [[[231.0], [212.0], [156.0], [164.0], [174.0],...  \n",
       "3  [[[24.0], [32.0], [36.0], [30.0], [32.0], [23....  \n",
       "4  [[[4.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b81b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.get_dummies(df5, columns=['emo'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8646699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixels</th>\n",
       "      <th>emotion_names</th>\n",
       "      <th>pixar1</th>\n",
       "      <th>pixar2</th>\n",
       "      <th>emo_arr1</th>\n",
       "      <th>emo_arr</th>\n",
       "      <th>emo_happy</th>\n",
       "      <th>emo_unhappy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Angry</td>\n",
       "      <td>[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63....</td>\n",
       "      <td>[[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...</td>\n",
       "      <td>[[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...</td>\n",
       "      <td>[[[70.0], [80.0], [82.0], [72.0], [58.0], [58....</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Angry</td>\n",
       "      <td>[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 111...</td>\n",
       "      <td>[[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...</td>\n",
       "      <td>[[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...</td>\n",
       "      <td>[[[151.0], [150.0], [147.0], [155.0], [148.0],...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Fear</td>\n",
       "      <td>[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 161...</td>\n",
       "      <td>[[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 16...</td>\n",
       "      <td>[[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 16...</td>\n",
       "      <td>[[[231.0], [212.0], [156.0], [164.0], [174.0],...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20....</td>\n",
       "      <td>[[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20...</td>\n",
       "      <td>[[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20...</td>\n",
       "      <td>[[[24.0], [32.0], [36.0], [30.0], [32.0], [23....</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[[4.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              pixels emotion_names  \\\n",
       "0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...         Angry   \n",
       "1  151 150 147 155 148 133 111 140 170 174 182 15...         Angry   \n",
       "2  231 212 156 164 174 138 161 173 182 200 106 38...          Fear   \n",
       "3  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...           Sad   \n",
       "4  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...       Neutral   \n",
       "\n",
       "                                              pixar1  \\\n",
       "0  [70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63....   \n",
       "1  [151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 111...   \n",
       "2  [231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 161...   \n",
       "3  [24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20....   \n",
       "4  [4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                              pixar2  \\\n",
       "0  [[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...   \n",
       "1  [[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...   \n",
       "2  [[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 16...   \n",
       "3  [[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20...   \n",
       "4  [[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                            emo_arr1  \\\n",
       "0  [[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...   \n",
       "1  [[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...   \n",
       "2  [[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 16...   \n",
       "3  [[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20...   \n",
       "4  [[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                             emo_arr  emo_happy  emo_unhappy  \n",
       "0  [[[70.0], [80.0], [82.0], [72.0], [58.0], [58....          0            1  \n",
       "1  [[[151.0], [150.0], [147.0], [155.0], [148.0],...          0            1  \n",
       "2  [[[231.0], [212.0], [156.0], [164.0], [174.0],...          0            1  \n",
       "3  [[[24.0], [32.0], [36.0], [30.0], [32.0], [23....          0            1  \n",
       "4  [[[4.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...          0            1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9da2d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['dums'] = df6[['emo_happy','emo_unhappy']].apply(lambda x: pd.Series([x.values]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6327363",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pth2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4ad6c53fb0a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpth2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pth2' is not defined"
     ]
    }
   ],
   "source": [
    "pth2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13a4b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.to_csv(pth2/'df_fer_top.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52b29c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35887, 9)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7 = pd.read_csv(pth2/'df_fer_top.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a39e6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixels</th>\n",
       "      <th>emotion_names</th>\n",
       "      <th>pixar1</th>\n",
       "      <th>pixar2</th>\n",
       "      <th>emo_arr1</th>\n",
       "      <th>emo_arr</th>\n",
       "      <th>emo_happy</th>\n",
       "      <th>emo_unhappy</th>\n",
       "      <th>dums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Angry</td>\n",
       "      <td>[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63....</td>\n",
       "      <td>[[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...</td>\n",
       "      <td>[[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...</td>\n",
       "      <td>[[[70.0], [80.0], [82.0], [72.0], [58.0], [58....</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Angry</td>\n",
       "      <td>[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 111...</td>\n",
       "      <td>[[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...</td>\n",
       "      <td>[[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...</td>\n",
       "      <td>[[[151.0], [150.0], [147.0], [155.0], [148.0],...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Fear</td>\n",
       "      <td>[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 161...</td>\n",
       "      <td>[[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 16...</td>\n",
       "      <td>[[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 16...</td>\n",
       "      <td>[[[231.0], [212.0], [156.0], [164.0], [174.0],...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20....</td>\n",
       "      <td>[[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20...</td>\n",
       "      <td>[[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20...</td>\n",
       "      <td>[[[24.0], [32.0], [36.0], [30.0], [32.0], [23....</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[[4.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              pixels emotion_names  \\\n",
       "0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...         Angry   \n",
       "1  151 150 147 155 148 133 111 140 170 174 182 15...         Angry   \n",
       "2  231 212 156 164 174 138 161 173 182 200 106 38...          Fear   \n",
       "3  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...           Sad   \n",
       "4  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...       Neutral   \n",
       "\n",
       "                                              pixar1  \\\n",
       "0  [70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63....   \n",
       "1  [151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 111...   \n",
       "2  [231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 161...   \n",
       "3  [24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20....   \n",
       "4  [4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                              pixar2  \\\n",
       "0  [[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...   \n",
       "1  [[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...   \n",
       "2  [[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 16...   \n",
       "3  [[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20...   \n",
       "4  [[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                            emo_arr1  \\\n",
       "0  [[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63...   \n",
       "1  [[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 11...   \n",
       "2  [[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 16...   \n",
       "3  [[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20...   \n",
       "4  [[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                             emo_arr  emo_happy  emo_unhappy  \\\n",
       "0  [[[70.0], [80.0], [82.0], [72.0], [58.0], [58....          0            1   \n",
       "1  [[[151.0], [150.0], [147.0], [155.0], [148.0],...          0            1   \n",
       "2  [[[231.0], [212.0], [156.0], [164.0], [174.0],...          0            1   \n",
       "3  [[[24.0], [32.0], [36.0], [30.0], [32.0], [23....          0            1   \n",
       "4  [[[4.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0...          0            1   \n",
       "\n",
       "     dums  \n",
       "0  [0, 1]  \n",
       "1  [0, 1]  \n",
       "2  [0, 1]  \n",
       "3  [0, 1]  \n",
       "4  [0, 1]  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bf61ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   pixels         35887 non-null  object\n",
      " 1   emotion_names  35887 non-null  object\n",
      " 2   pixar1         35887 non-null  object\n",
      " 3   pixar2         35887 non-null  object\n",
      " 4   emo_arr1       35887 non-null  object\n",
      " 5   emo_arr        35887 non-null  object\n",
      " 6   emo_happy      35887 non-null  uint8 \n",
      " 7   emo_unhappy    35887 non-null  uint8 \n",
      " 8   dums           35887 non-null  object\n",
      "dtypes: object(7), uint8(2)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df6.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e713cdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df6.pixar1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "196f6986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.emo_arr[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1783190",
   "metadata": {},
   "source": [
    "# EL wueno es emo_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3aae1df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35887, 48, 48, 1), (35887, 2))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = (np.stack(df6['emo_arr'])) / 255.0\n",
    "y = np.stack(df6.dums)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "350ff199",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_testval, y_train, y_testval = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "474d2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_testval,y_testval,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f537d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c476421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 48, 48, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47c6f15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8cc386ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3589, 48, 48, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f90cc894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3589, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "957c8896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3589, 48, 48, 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "867fdb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3589, 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fa0feb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3589, 48, 48, 1), (3589, 48, 48, 1), (3589, 2), (3589, 2))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, X_val.shape, y_test.shape, y_val.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cbb472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5fe0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aaf90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfImag(path, new_path):\n",
    "    \n",
    "    # ROCKET\n",
    "    \"\"\"\n",
    "    recibe carpeta, en cada foto de esa carpeta:\n",
    "    lectura\n",
    "    to gray\n",
    "    facecascade\n",
    "    por xywh en cada cara:\n",
    "        array\n",
    "        reshape array a 2d\n",
    "        stack array 3d\n",
    "        normalizar\n",
    "        expand 4d\n",
    "    devuelve array x cada foto para pasarselo al modelo\n",
    "    \"\"\"\n",
    "    counter_imgs = 0\n",
    "    counter_faces = 0\n",
    "    \n",
    "    X_ = pd.Series([], dtype='float64')\n",
    "    \n",
    "    for file in sorted(path.iterdir()):\n",
    "        \n",
    "        counter_imgs += 1\n",
    "\n",
    "        input_img1 = cv2.imread(str(file))\n",
    "        input_img2 = cv2.cvtColor(input_img1, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(input_img2, 1.25, 6)\n",
    "        \n",
    "        for (x,y,w,h) in faces:\n",
    "            \n",
    "            counter_faces += 1\n",
    "            img_data1 = input_img2 [y:y+h,x:x+w]\n",
    "            img_data2 = cv2.resize (img_data1,(48,48))\n",
    "\n",
    "            img_data3 = np.stack(img_data2) \n",
    "            img_data4 = img_data2 / 255.0\n",
    "            img_data5 = img_data3 / 255.0\n",
    "            \n",
    "            img_data6 = np.expand_dims(img_data5,axis=0).reshape(np.expand_dims(img_data5,axis=0).shape[0], 48, 48, 1)\n",
    "            \n",
    "            print(img_data6.shape)\n",
    "            print(img_data6)\n",
    "            \n",
    "            img_datashow = img_data3*255\n",
    "            img_show = Image.fromarray(img_datashow)\n",
    "            file_to_save = file.name.replace(\".\",f\"_face{counter_faces}.\")\n",
    "            img_show.save(str(new_path/file_to_save))\n",
    "            \n",
    "            counter_faces = 0\n",
    "            \n",
    "            arr_for_model = img_data6\n",
    "            \n",
    "            \n",
    "            return arr_for_model\n",
    "    \n",
    "    print('YAAA!')    \n",
    "    return counter_imgs\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5307b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    input_shape = (48,48,1)\n",
    "    #1st convolution layer\n",
    "    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    #2nd convolution layer\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #3rd convolution layer\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    #model.add(Dense(1, activation='sigmoid')) (should be used for binary class but giving error)\n",
    "\n",
    "    my_optimiser = tf.keras.optimizers.Adam(\n",
    "    learning_rate = 0.001, beta_1=0.9, beta_2=0.999, \n",
    "        epsilon=1e-07, amsgrad=False, name='Adam')\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'],\n",
    "                  optimizer=my_optimiser)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "693777ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28709, 48, 48, 1), (28709, 2))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6ea9f5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3589, 48, 48, 1), (3589, 2))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361cd185",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_2 = base_model()\n",
    "\n",
    "model_2.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=20,\n",
    "            verbose=2, \n",
    "            batch_size=50)\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e70d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save(\"../src/model_v2_epoch30happyunhappy.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70718ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ea588",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model_2.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cccc8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath2 = os.path.join(\"../src/model_v2_epoch30happyunhappy.hdf5\")\n",
    "\n",
    "checkpoint2 = ModelCheckpoint(\n",
    "    filepath2,\n",
    "    monitor='val_acc',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c940dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = Path.cwd().parent/'src'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7c0be2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfImag(demo_imgs, demo_imgs_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "36f64bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "575/575 [==============================] - 1333s 2s/step - loss: 0.5415 - accuracy: 0.7466 - val_loss: 0.4907 - val_accuracy: 0.7802\n",
      "Epoch 2/12\n",
      "575/575 [==============================] - 1451s 3s/step - loss: 0.3963 - accuracy: 0.8266 - val_loss: 0.3725 - val_accuracy: 0.8370\n",
      "Epoch 3/12\n",
      "575/575 [==============================] - 1467s 3s/step - loss: 0.3203 - accuracy: 0.8697 - val_loss: 0.3204 - val_accuracy: 0.8688\n",
      "Epoch 4/12\n",
      "575/575 [==============================] - 1375s 2s/step - loss: 0.2839 - accuracy: 0.8862 - val_loss: 0.3127 - val_accuracy: 0.8716\n",
      "Epoch 5/12\n",
      "575/575 [==============================] - 1578s 3s/step - loss: 0.2618 - accuracy: 0.8944 - val_loss: 0.3230 - val_accuracy: 0.8704\n",
      "Epoch 6/12\n",
      "575/575 [==============================] - 1520s 3s/step - loss: 0.2473 - accuracy: 0.9019 - val_loss: 0.2718 - val_accuracy: 0.8927\n",
      "Epoch 7/12\n",
      "575/575 [==============================] - 1502s 3s/step - loss: 0.2345 - accuracy: 0.9108 - val_loss: 0.3353 - val_accuracy: 0.8704\n",
      "Epoch 8/12\n",
      "575/575 [==============================] - 1561s 3s/step - loss: 0.2284 - accuracy: 0.9106 - val_loss: 0.2586 - val_accuracy: 0.9005\n",
      "Epoch 9/12\n",
      "575/575 [==============================] - 1622s 3s/step - loss: 0.2134 - accuracy: 0.9173 - val_loss: 0.3254 - val_accuracy: 0.8738\n",
      "Epoch 10/12\n",
      "575/575 [==============================] - 1497s 3s/step - loss: 0.2066 - accuracy: 0.9200 - val_loss: 0.2577 - val_accuracy: 0.9042\n",
      "Epoch 11/12\n",
      "575/575 [==============================] - 1335s 2s/step - loss: 0.1945 - accuracy: 0.9247 - val_loss: 0.2684 - val_accuracy: 0.9050\n",
      "Epoch 12/12\n",
      "575/575 [==============================] - 1325s 2s/step - loss: 0.1878 - accuracy: 0.9295 - val_loss: 0.3093 - val_accuracy: 0.8919\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 48, 48, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 48, 48, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 24, 24, 128)       204928    \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 24, 24, 128)       409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,786,370\n",
      "Trainable params: 2,785,218\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3 = base_model()\n",
    "\n",
    "model_3.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=12,\n",
    "            verbose=1, \n",
    "            batch_size=50)\n",
    "\n",
    "model_3.summary()\n",
    "model_3.save(\"../src/model_v3_epoch12happyunhappy.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7837026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.save(\"../src/model_v3.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "84a565e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model_3.to_json()\n",
    "name_3 = 'model_v3.hdf5'\n",
    "model_3.save_weights(name_3)\n",
    "with open(name_3+'.json', \"w\") as json_file:\n",
    "    json.dump(model_json, json_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9bcd1b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.load_weights(\"model_v3.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2725a6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 36s - loss: 0.2662 - accuracy: 0.9042\n",
      "Accuracy: 90.42%\n",
      "Test loss: 0.26619917154312134\n",
      "Test accuracy: 0.9041515588760376\n"
     ]
    }
   ],
   "source": [
    "scores = model_3.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "98c20017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'90.42%'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"%.2f%%\" % (scores[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "373aec34",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d6e7b99e95fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_3' is not defined"
     ]
    }
   ],
   "source": [
    "scores = model_3.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d4fc2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = \"%.2f%%\" % (scores[1]*100)\n",
    "test_loss = scores[0]\n",
    "test_accuracy = scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0b3ba3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.42% 0.26619917154312134 0.9041515588760376\n"
     ]
    }
   ],
   "source": [
    "print(accuracy,test_loss,test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ff9c5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filepath='Checkpoint_{epoch:02d}_{val_accuracy:.2f}'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d4deab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath3 = os.path.join(\"../models/model_v2_.hdf5\")\n",
    "\n",
    "checkpoint3 = ModelCheckpoint(\n",
    "    filepath3,\n",
    "    monitor='val_acc',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='max')\n",
    "callbacks_list = [checkpoint3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfImag2(path):\n",
    "    print ('transforming image from {}'.format(path))\n",
    "\n",
    "    input_img=cv2.imread(path)\n",
    "    input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(input_img, 1.25, 6)\n",
    "    x,y,w,h = faces[0]\n",
    "    img_data= input_img[y:y+h,x:x+w]\n",
    "    img_data=cv2.resize(img_data,(48,48))\n",
    "    \n",
    "    img_data = np.stack(img_data)\n",
    "    img_data = img_data / 255.0\n",
    "    \n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48561131",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIC = transfImag2('foto.jpg') # transform pic\n",
    "input_img=cv2.imread('foto.jpg') # get the array of the original pic\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(input_img) # original pic\n",
    "plt.subplot(122)\n",
    "plt.imshow(Image.fromarray(PIC.squeeze()*255)) # transformed pic\n",
    "\n",
    "PIC = np.expand_dims(PIC,axis=0).reshape(np.expand_dims(PIC,axis=0).shape[0], 48, 48, 1)\n",
    "print(PIC.shape)\n",
    "pred2 = model_1.predict(PIC)[0]\n",
    "print(\"Probs -> happy:{0:.5f} unhappy:{1:.5f}\".format(pred2[0],pred2[1]))\n",
    "\n",
    "happy = pred2[0]\n",
    "unhappy = pred2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fd4286",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1278515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if happy > 0.8:\n",
    "    st.write(\"Llego mama\")\n",
    "    image = blavblabla\n",
    "    st.image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ed9a097c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEpoch 1/12\\n575/575 [==============================] - 1333s 2s/step - loss: 0.5415 - accuracy: 0.7466 - val_loss: 0.4907 - val_accuracy: 0.7802\\nEpoch 2/12\\n575/575 [==============================] - 1451s 3s/step - loss: 0.3963 - accuracy: 0.8266 - val_loss: 0.3725 - val_accuracy: 0.8370\\nEpoch 3/12\\n575/575 [==============================] - 1467s 3s/step - loss: 0.3203 - accuracy: 0.8697 - val_loss: 0.3204 - val_accuracy: 0.8688\\nEpoch 4/12\\n575/575 [==============================] - 1375s 2s/step - loss: 0.2839 - accuracy: 0.8862 - val_loss: 0.3127 - val_accuracy: 0.8716\\nEpoch 5/12\\n575/575 [==============================] - 1578s 3s/step - loss: 0.2618 - accuracy: 0.8944 - val_loss: 0.3230 - val_accuracy: 0.8704\\nEpoch 6/12\\n575/575 [==============================] - 1520s 3s/step - loss: 0.2473 - accuracy: 0.9019 - val_loss: 0.2718 - val_accuracy: 0.8927\\nEpoch 7/12\\n575/575 [==============================] - 1502s 3s/step - loss: 0.2345 - accuracy: 0.9108 - val_loss: 0.3353 - val_accuracy: 0.8704\\nEpoch 8/12\\n575/575 [==============================] - 1561s 3s/step - loss: 0.2284 - accuracy: 0.9106 - val_loss: 0.2586 - val_accuracy: 0.9005\\nEpoch 9/12\\n575/575 [==============================] - 1622s 3s/step - loss: 0.2134 - accuracy: 0.9173 - val_loss: 0.3254 - val_accuracy: 0.8738\\nEpoch 10/12\\n575/575 [==============================] - 1497s 3s/step - loss: 0.2066 - accuracy: 0.9200 - val_loss: 0.2577 - val_accuracy: 0.9042\\nEpoch 11/12\\n575/575 [==============================] - 1335s 2s/step - loss: 0.1945 - accuracy: 0.9247 - val_loss: 0.2684 - val_accuracy: 0.9050\\nEpoch 12/12\\n575/575 [==============================] - 1325s 2s/step - loss: 0.1878 - accuracy: 0.9295 - val_loss: 0.3093 - val_accuracy: 0.8919\\n\\n\\nModel: \"sequential_5\"\\n_________________________________________________________________\\nLayer (type)                 Output Shape              Param #   \\n=================================================================\\nconv2d_30 (Conv2D)           (None, 48, 48, 64)        1664      \\n_________________________________________________________________\\nconv2d_31 (Conv2D)           (None, 48, 48, 64)        102464    \\n_________________________________________________________________\\nbatch_normalization_20 (Batc (None, 48, 48, 64)        256       \\n_________________________________________________________________\\nmax_pooling2d_15 (MaxPooling (None, 24, 24, 64)        0         \\n_________________________________________________________________\\ndropout_20 (Dropout)         (None, 24, 24, 64)        0         \\n_________________________________________________________________\\nconv2d_32 (Conv2D)           (None, 24, 24, 128)       204928    \\n_________________________________________________________________\\nconv2d_33 (Conv2D)           (None, 24, 24, 128)       409728    \\n_________________________________________________________________\\nbatch_normalization_21 (Batc (None, 24, 24, 128)       512       \\n_________________________________________________________________\\nmax_pooling2d_16 (MaxPooling (None, 12, 12, 128)       0         \\n_________________________________________________________________\\ndropout_21 (Dropout)         (None, 12, 12, 128)       0         \\n_________________________________________________________________\\nconv2d_34 (Conv2D)           (None, 12, 12, 256)       295168    \\n_________________________________________________________________\\nconv2d_35 (Conv2D)           (None, 12, 12, 256)       590080    \\n_________________________________________________________________\\nbatch_normalization_22 (Batc (None, 12, 12, 256)       1024      \\n_________________________________________________________________\\nmax_pooling2d_17 (MaxPooling (None, 6, 6, 256)         0         \\n_________________________________________________________________\\ndropout_22 (Dropout)         (None, 6, 6, 256)         0         \\n_________________________________________________________________\\nflatten_5 (Flatten)          (None, 9216)              0         \\n_________________________________________________________________\\ndense_11 (Dense)             (None, 128)               1179776   \\n_________________________________________________________________\\nbatch_normalization_23 (Batc (None, 128)               512       \\n_________________________________________________________________\\nactivation_10 (Activation)   (None, 128)               0         \\n_________________________________________________________________\\ndropout_23 (Dropout)         (None, 128)               0         \\n_________________________________________________________________\\ndense_12 (Dense)             (None, 2)                 258       \\n_________________________________________________________________\\nactivation_11 (Activation)   (None, 2)                 0         \\n=================================================================\\n\\nTotal params: 2,786,370\\nTrainable params: 2,785,218\\nNon-trainable params: 1,152\\n\\n'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Epoch 1/12\n",
    "575/575 [==============================] - 1333s 2s/step - loss: 0.5415 - accuracy: 0.7466 - val_loss: 0.4907 - val_accuracy: 0.7802\n",
    "Epoch 2/12\n",
    "575/575 [==============================] - 1451s 3s/step - loss: 0.3963 - accuracy: 0.8266 - val_loss: 0.3725 - val_accuracy: 0.8370\n",
    "Epoch 3/12\n",
    "575/575 [==============================] - 1467s 3s/step - loss: 0.3203 - accuracy: 0.8697 - val_loss: 0.3204 - val_accuracy: 0.8688\n",
    "Epoch 4/12\n",
    "575/575 [==============================] - 1375s 2s/step - loss: 0.2839 - accuracy: 0.8862 - val_loss: 0.3127 - val_accuracy: 0.8716\n",
    "Epoch 5/12\n",
    "575/575 [==============================] - 1578s 3s/step - loss: 0.2618 - accuracy: 0.8944 - val_loss: 0.3230 - val_accuracy: 0.8704\n",
    "Epoch 6/12\n",
    "575/575 [==============================] - 1520s 3s/step - loss: 0.2473 - accuracy: 0.9019 - val_loss: 0.2718 - val_accuracy: 0.8927\n",
    "Epoch 7/12\n",
    "575/575 [==============================] - 1502s 3s/step - loss: 0.2345 - accuracy: 0.9108 - val_loss: 0.3353 - val_accuracy: 0.8704\n",
    "Epoch 8/12\n",
    "575/575 [==============================] - 1561s 3s/step - loss: 0.2284 - accuracy: 0.9106 - val_loss: 0.2586 - val_accuracy: 0.9005\n",
    "Epoch 9/12\n",
    "575/575 [==============================] - 1622s 3s/step - loss: 0.2134 - accuracy: 0.9173 - val_loss: 0.3254 - val_accuracy: 0.8738\n",
    "Epoch 10/12\n",
    "575/575 [==============================] - 1497s 3s/step - loss: 0.2066 - accuracy: 0.9200 - val_loss: 0.2577 - val_accuracy: 0.9042\n",
    "Epoch 11/12\n",
    "575/575 [==============================] - 1335s 2s/step - loss: 0.1945 - accuracy: 0.9247 - val_loss: 0.2684 - val_accuracy: 0.9050\n",
    "Epoch 12/12\n",
    "575/575 [==============================] - 1325s 2s/step - loss: 0.1878 - accuracy: 0.9295 - val_loss: 0.3093 - val_accuracy: 0.8919\n",
    "\n",
    "\n",
    "Model: \"sequential_5\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d_30 (Conv2D)           (None, 48, 48, 64)        1664      \n",
    "_________________________________________________________________\n",
    "conv2d_31 (Conv2D)           (None, 48, 48, 64)        102464    \n",
    "_________________________________________________________________\n",
    "batch_normalization_20 (Batc (None, 48, 48, 64)        256       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_15 (MaxPooling (None, 24, 24, 64)        0         \n",
    "_________________________________________________________________\n",
    "dropout_20 (Dropout)         (None, 24, 24, 64)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_32 (Conv2D)           (None, 24, 24, 128)       204928    \n",
    "_________________________________________________________________\n",
    "conv2d_33 (Conv2D)           (None, 24, 24, 128)       409728    \n",
    "_________________________________________________________________\n",
    "batch_normalization_21 (Batc (None, 24, 24, 128)       512       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_16 (MaxPooling (None, 12, 12, 128)       0         \n",
    "_________________________________________________________________\n",
    "dropout_21 (Dropout)         (None, 12, 12, 128)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_34 (Conv2D)           (None, 12, 12, 256)       295168    \n",
    "_________________________________________________________________\n",
    "conv2d_35 (Conv2D)           (None, 12, 12, 256)       590080    \n",
    "_________________________________________________________________\n",
    "batch_normalization_22 (Batc (None, 12, 12, 256)       1024      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_17 (MaxPooling (None, 6, 6, 256)         0         \n",
    "_________________________________________________________________\n",
    "dropout_22 (Dropout)         (None, 6, 6, 256)         0         \n",
    "_________________________________________________________________\n",
    "flatten_5 (Flatten)          (None, 9216)              0         \n",
    "_________________________________________________________________\n",
    "dense_11 (Dense)             (None, 128)               1179776   \n",
    "_________________________________________________________________\n",
    "batch_normalization_23 (Batc (None, 128)               512       \n",
    "_________________________________________________________________\n",
    "activation_10 (Activation)   (None, 128)               0         \n",
    "_________________________________________________________________\n",
    "dropout_23 (Dropout)         (None, 128)               0         \n",
    "_________________________________________________________________\n",
    "dense_12 (Dense)             (None, 2)                 258       \n",
    "_________________________________________________________________\n",
    "activation_11 (Activation)   (None, 2)                 0         \n",
    "=================================================================\n",
    "\n",
    "Total params: 2,786,370\n",
    "Trainable params: 2,785,218\n",
    "Non-trainable params: 1,152\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e61bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAAR CASCADE CLASSIFIER\n",
    "def detect_face_eyes_smile(pth,new_pth):\n",
    "    \"\"\"\n",
    "    Extracts all .jpg files from local path, \n",
    "    calls on haar cascade classifiers (frontalface, eyes and smile) \n",
    "    and draws detection rectangles on each .jpg \n",
    "    \n",
    "    Takes: local path of directory with .jpg images\n",
    "    \n",
    "    Returns: individual windows for .jpg files with detection rectangles for face, eyes and smile\n",
    "    \"\"\"\n",
    "\n",
    "    counter_imgs = 0\n",
    "    counter_faces = 0\n",
    "    counter_smiles = 0\n",
    "    counter_eyes = 0\n",
    "    face_cascade = cv2.CascadeClassifier('../src/haarcascade_frontalface_default.xml')\n",
    "    eye_cascade = cv2.CascadeClassifier('../src/haarcascade_eye.xml')\n",
    "    smile_cascade = cv2.CascadeClassifier('../src/haarcascade_smile.xml')\n",
    "    \n",
    "    for file in sorted(pth.iterdir()):\n",
    "        if file.suffix != '.jpg':\n",
    "            pass\n",
    "        else:\n",
    "            counter_imgs += 1\n",
    "            print(file.name)\n",
    "            \n",
    "            img = cv2.imread(str(file))\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            #plt.imshow(img)\n",
    "\n",
    "            # FRONTAL FACE \n",
    "            \n",
    "            faces = face_cascade.detectMultiScale(\n",
    "                img_gray, \n",
    "                scaleFactor=1.06,                \n",
    "                minNeighbors=7,\n",
    "                minSize=(30, 30), \n",
    "                flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "            if faces is None:\n",
    "                print(\"No Face Found\")\n",
    "\n",
    "            for (fx,fy,fw,fh) in faces:\n",
    "                \n",
    "                counter_faces += 1\n",
    "                roi_gray = img_gray [fy:fy+fh, fx:fx+fw] # region of interest for detection\n",
    "                roi_gray2 = cv2.resize (roi_gray, (48,48))\n",
    "                roi_gray3 = np.stack(roi_gray2)\n",
    "                roi_gray4 = roi_gray2 / 255\n",
    "                \n",
    "                roi_color = img[fy:fy+fh, fx:fx+fw] # region of interest for mapping rectangle\n",
    "                roi_color2 = cv2.resize (roi_color, (48,48))\n",
    "                roi_color3 = np.stack(roi_color2)\n",
    "                roi_color4 = roi_color2 / 255\n",
    "                \n",
    "                cv2.rectangle(\n",
    "                    img,\n",
    "                    (fx,fy),\n",
    "                    (fx+fw,fy+fh),\n",
    "                    #(127,0,255),\n",
    "                    (0,255,0),\n",
    "                    2)\n",
    "\n",
    "                # SMILES \n",
    "\n",
    "                smiles = smile_cascade.detectMultiScale(\n",
    "                    roi_gray, \n",
    "                    scaleFactor = 1.35, \n",
    "                    minNeighbors = 8)\n",
    "\n",
    "                for (sx, sy, sw, sh) in smiles:\n",
    "                    counter_smiles += 1\n",
    "                    cv2.rectangle(\n",
    "                        roi_color,\n",
    "                        (sx, sy),\n",
    "                        (sx + sw, sy + sh),\n",
    "                        #(255, 0, 130),\n",
    "                        #(0,220,80),\n",
    "                        (127,0,255),\n",
    "                        1)\n",
    "\n",
    "                # EYES\n",
    "\n",
    "                eyes = eye_cascade.detectMultiScale(\n",
    "                    roi_gray,\n",
    "                    scaleFactor=1.05,\n",
    "                    minNeighbors = 6)\n",
    "\n",
    "                for (ex,ey,ew,eh) in eyes:\n",
    "                    counter_eyes += 1\n",
    "                    cv2.rectangle(\n",
    "                        roi_color, \n",
    "                        (ex , ey),\n",
    "                        (ex + ew, ey + eh),\n",
    "                        (0,255,255),\n",
    "                        1)\n",
    "            \n",
    "                # save images with detected regions\n",
    "                file_to_save = file.name.replace(\".\",f\"_face{counter_faces}.\")\n",
    "                \n",
    "                #cv2.imwrite(str(pth.parent/'demo_faces'/file_to_save),img)\n",
    "                cv2.imwrite(str(new_pth/file_to_save),roi_color)\n",
    "                counter_imgs = 0\n",
    "                counter_faces = 0\n",
    "            # show the output frame\n",
    "            cv2.imshow(f\"img{file_to_save}\", img)\n",
    "            key = cv2.waitKey(100) & 0xFF\n",
    "            \n",
    "    cv2.destroyAllWindows(f\"img{file_to_save}\")\n",
    "    \n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "            if key == ord(\"q\"):\n",
    "                # do a bit of cleanup\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "        \n",
    "    # do a bit of cleanup\n",
    "    cv2.destroyAllWindows()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168dd7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_imgs = Path.cwd().parent/'demo'\n",
    "demo_imgs_faces = Path.cwd().parent/demo2\n",
    "demo1 = demo_imgs/'A_0.jpg'\n",
    "demo2 = demo_imgs/'demooo_01.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3705e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../src/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('../src/haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('../src/haarcascade_smile.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "71fb5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath='Checkpoint_{epoch:02d}_{val_accuracy:.2f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "741b7b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%.2f%%` not found.\n"
     ]
    }
   ],
   "source": [
    "%.2f%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fc56ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd40eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(str(pth.parent/*'_haar'/file.name),roi_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(pth.parent/'*_haar'/file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef1dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9093fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth2 = Path.home()/'Iron'/'data_processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f60bdd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.read_csv(pth2/'df_fer_top.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "517751ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pixels</th>\n",
       "      <th>emotion_names</th>\n",
       "      <th>pixar1</th>\n",
       "      <th>pixar2</th>\n",
       "      <th>emo_arr1</th>\n",
       "      <th>emo_arr</th>\n",
       "      <th>emo_happy</th>\n",
       "      <th>emo_unhappy</th>\n",
       "      <th>dums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Angry</td>\n",
       "      <td>[70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63....</td>\n",
       "      <td>[[ 70.  80.  82. ...  52.  43.  41.]\\n [ 65.  ...</td>\n",
       "      <td>[[ 70.  80.  82. ...  52.  43.  41.]\\n [ 65.  ...</td>\n",
       "      <td>[[[ 70.]\\n  [ 80.]\\n  [ 82.]\\n  ...\\n  [ 52.]\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Angry</td>\n",
       "      <td>[151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 111...</td>\n",
       "      <td>[[151. 150. 147. ... 129. 140. 120.]\\n [151. 1...</td>\n",
       "      <td>[[151. 150. 147. ... 129. 140. 120.]\\n [151. 1...</td>\n",
       "      <td>[[[151.]\\n  [150.]\\n  [147.]\\n  ...\\n  [129.]\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Fear</td>\n",
       "      <td>[231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 161...</td>\n",
       "      <td>[[231. 212. 156. ...  44.  27.  16.]\\n [229. 1...</td>\n",
       "      <td>[[231. 212. 156. ...  44.  27.  16.]\\n [229. 1...</td>\n",
       "      <td>[[[231.]\\n  [212.]\\n  [156.]\\n  ...\\n  [ 44.]\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20....</td>\n",
       "      <td>[[ 24.  32.  36. ... 173. 172. 173.]\\n [ 25.  ...</td>\n",
       "      <td>[[ 24.  32.  36. ... 173. 172. 173.]\\n [ 25.  ...</td>\n",
       "      <td>[[[ 24.]\\n  [ 32.]\\n  [ 36.]\\n  ...\\n  [173.]\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[ 4.  0.  0. ... 27. 24. 25.]\\n [ 1.  0.  0. ...</td>\n",
       "      <td>[[ 4.  0.  0. ... 27. 24. 25.]\\n [ 1.  0.  0. ...</td>\n",
       "      <td>[[[ 4.]\\n  [ 0.]\\n  [ 0.]\\n  ...\\n  [27.]\\n  [...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             pixels  \\\n",
       "0           0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...   \n",
       "1           1  151 150 147 155 148 133 111 140 170 174 182 15...   \n",
       "2           2  231 212 156 164 174 138 161 173 182 200 106 38...   \n",
       "3           3  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...   \n",
       "4           4  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...   \n",
       "\n",
       "  emotion_names                                             pixar1  \\\n",
       "0         Angry  [70.0, 80.0, 82.0, 72.0, 58.0, 58.0, 60.0, 63....   \n",
       "1         Angry  [151.0, 150.0, 147.0, 155.0, 148.0, 133.0, 111...   \n",
       "2          Fear  [231.0, 212.0, 156.0, 164.0, 174.0, 138.0, 161...   \n",
       "3           Sad  [24.0, 32.0, 36.0, 30.0, 32.0, 23.0, 19.0, 20....   \n",
       "4       Neutral  [4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                              pixar2  \\\n",
       "0  [[ 70.  80.  82. ...  52.  43.  41.]\\n [ 65.  ...   \n",
       "1  [[151. 150. 147. ... 129. 140. 120.]\\n [151. 1...   \n",
       "2  [[231. 212. 156. ...  44.  27.  16.]\\n [229. 1...   \n",
       "3  [[ 24.  32.  36. ... 173. 172. 173.]\\n [ 25.  ...   \n",
       "4  [[ 4.  0.  0. ... 27. 24. 25.]\\n [ 1.  0.  0. ...   \n",
       "\n",
       "                                            emo_arr1  \\\n",
       "0  [[ 70.  80.  82. ...  52.  43.  41.]\\n [ 65.  ...   \n",
       "1  [[151. 150. 147. ... 129. 140. 120.]\\n [151. 1...   \n",
       "2  [[231. 212. 156. ...  44.  27.  16.]\\n [229. 1...   \n",
       "3  [[ 24.  32.  36. ... 173. 172. 173.]\\n [ 25.  ...   \n",
       "4  [[ 4.  0.  0. ... 27. 24. 25.]\\n [ 1.  0.  0. ...   \n",
       "\n",
       "                                             emo_arr  emo_happy  emo_unhappy  \\\n",
       "0  [[[ 70.]\\n  [ 80.]\\n  [ 82.]\\n  ...\\n  [ 52.]\\...          0            1   \n",
       "1  [[[151.]\\n  [150.]\\n  [147.]\\n  ...\\n  [129.]\\...          0            1   \n",
       "2  [[[231.]\\n  [212.]\\n  [156.]\\n  ...\\n  [ 44.]\\...          0            1   \n",
       "3  [[[ 24.]\\n  [ 32.]\\n  [ 36.]\\n  ...\\n  [173.]\\...          0            1   \n",
       "4  [[[ 4.]\\n  [ 0.]\\n  [ 0.]\\n  ...\\n  [27.]\\n  [...          0            1   \n",
       "\n",
       "    dums  \n",
       "0  [0 1]  \n",
       "1  [0 1]  \n",
       "2  [0 1]  \n",
       "3  [0 1]  \n",
       "4  [0 1]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a552e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1096f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.machinecurve.com/index.php/2020/04/13/how-to-use-h5py-and-keras-to-train-with-data-from-hdf5-files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51c411b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_pth = Path.cwd().parent/'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6dc62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8546dacc",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: ../src/model_v3.hdf5.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7df59da76665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../src/model_v3.hdf5.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   raise IOError(\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[0;31m# Look for metadata file or parse the SavedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSavedMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m   \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m   \u001b[0mobject_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0mpath_to_metadata_pb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_METADATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/iron/lib/python3.8/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     raise IOError(\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: ../src/model_v3.hdf5.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "model = load_model(\"../src/model_v3.hdf5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f95cb5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff20e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5897404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8408e6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iron",
   "language": "python",
   "name": "iron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
